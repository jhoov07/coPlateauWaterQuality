rm(list=ls())
#Load RF model
classifier_RF<-readRDS("./03_modelOuput/01_rf/2024-07-30_mtry5_cv10_bU30_final_model_rf.rds")
#Load data
data = read.csv("./01_data/Cleaned_U_GIS_Filtered_Joe.csv",
na.strings = c("NULL", "NA")) #Probably need to simplify the path so the script and data are in the same folder for the HPC
data <- data[complete.cases(data), ]
#Subset to test set
test<-subset(data, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = test[,-c(1:5,208:215, 217:218)])
confusionMatrix(y_pred, factor(test[,216]))
# Plotting model
plot(classifier_RF)
#Calculate variable importance
gbmImp <- varImp(classifier_RF, scale = FALSE)
gbmImp
#Plot variable importance
# - Variable importance
plot(gbmImp, top=10)
setwd("~/Desktop")
data = read.csv("nurewtr.csv")
# only keeps rows with "UT", "CO", "AZ", "NM" in state collum
data1 <- data[data$state %in% c("UT", "CO", "AZ", "NM"), ]
#removes all variables besides "welldpth", "latitude", "longitude", "u_dn_ppb", "u_fl_ppb", "state"
filtered_data <- data1[, c("rec_no","welldpth", "latitude", "longitude", "u_dn_ppb", "u_fl_ppb", "state")]
#shows how many NAs are in the data before cleaning
na_count_before <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb before replacement:", na_count_before, "\n")
#replace NA values in u_fl_ppb with corresponding values from u_dn_ppb
filtered_data$u_fl_ppb[is.na(filtered_data$u_fl_ppb)] <- filtered_data$u_dn_ppb[is.na(filtered_data$u_fl_ppb)]
#shows how many NAs are in the data before cleaning after cleaning
na_count_after <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb after replacement:", na_count_after, "\n")
#I did this to check my work,
# makes dataframe with all rows with NAs in both u_fl_ppb and u_dn_ppb to check if it matched # of NAs
na_rows <- which(is.na(filtered_data$u_fl_ppb))
na_filtered_data <- filtered_data[is.na(filtered_data$u_fl_ppb), ]
table(na_filtered_data$u_fl_ppb)
write.csv(filtered_data, file = "~/Desktop/5New_U_data.csv", row.names = FALSE)
data1 <- data[data$state %in% c("UT", "CO", "AZ", "NM"), ]
#removes all variables besides "welldpth", "latitude", "longitude", "u_dn_ppb", "u_fl_ppb", "state"
filtered_data <- data1[, c("rec_no","welldpth", "latitude", "longitude", "u_dn_ppb", "u_fl_ppb", "state")]
#write.csv(filtered_data, file = "~/Desktop/New_U_data.csv", row.names = FALSE)
# combining u_fl_ppb and u_dn_ppb
#shows how many NAs are in the data before cleaning
na_count_before <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb before replacement:", na_count_before, "\n")
#replace NA values in u_fl_ppb with corresponding values from u_dn_ppb
filtered_data$u_fl_ppb[is.na(filtered_data$u_fl_ppb)] <- filtered_data$u_dn_ppb[is.na(filtered_data$u_fl_ppb)]
#shows how many NAs are in the data before cleaning after cleaning
na_count_after <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb after replacement:", na_count_after, "\n")
#I did this to check my work,
# makes dataframe with all rows with NAs in both u_fl_ppb and u_dn_ppb to check if it matched # of NAs
na_rows <- which(is.na(filtered_data$u_fl_ppb))
na_filtered_data <- filtered_data[is.na(filtered_data$u_fl_ppb), ]
table(na_filtered_data$u_fl_ppb)
View(na_filtered_data)
#shows how many NAs are in the data before cleaning
na_count_before <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb before replacement:", na_count_before, "\n")
#replace NA values in u_fl_ppb with corresponding values from u_dn_ppb
filtered_data$u_fl_ppb[is.na(filtered_data$u_fl_ppb)] <- filtered_data$u_dn_ppb[is.na(filtered_data$u_fl_ppb)]
View(filtered_data)
#shows how many NAs are in the data before cleaning after cleaning
na_count_after <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb after replacement:", na_count_after, "\n")
#I did this to check my work,
# makes dataframe with all rows with NAs in both u_fl_ppb and u_dn_ppb to check if it matched # of NAs
na_rows <- which(is.na(filtered_data$u_fl_ppb))
na_filtered_data <- filtered_data[is.na(filtered_data$u_fl_ppb), ]
table(na_filtered_data$u_fl_ppb)
#take absolute value of field so there are no negative values; negatives mean less than that concentration
filtered_data$u_fl_ppb<-abs(filtered_data$u_fl_ppb)
#take absolute value of field so there are no negative values; negatives mean less than that concentration
filtered_data$u_fl_ppb<-abs(filtered_data$u_fl_ppb); summary(filtered_data$u_fl_ppb)
#shows how many NAs are in the data before cleaning after cleaning
na_count_after <- sum(is.na(filtered_data$u_fl_ppb))
cat("Number of NAs in u_fl_ppb after replacement:", na_count_after, "\n")
#I did this to check my work,
# makes dataframe with all rows with NAs in both u_fl_ppb and u_dn_ppb to check if it matched # of NAs
na_rows <- which(is.na(filtered_data$u_fl_ppb))
na_filtered_data <- filtered_data[is.na(filtered_data$u_fl_ppb), ]
table(na_filtered_data$u_fl_ppb)
write.csv(filtered_data, file = "~/Desktop/6New_U_data.csv", row.names = FALSE)
getwd()
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality")
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality")
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data <- colnames(bfi48grd_ProjectRaster2, baseflow)
data <- colnames(PRISM_ppt_30yr_ProjectRaster1, prism30yr)
?colnames
#Rename fields in NURE dataset
colnames(data$bfi48grd_ProjectRaster2) <- "baseflow"
#Rename fields in NURE dataset
colnames(data[1]) <- "baseflow"
#Rename fields in NURE dataset
colnames(data[,1]) <- "baseflow"
#Rename fields in NURE dataset
colnames(data[,5]) <- "baseflow"
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<-data %>%
rename(data, bfi48grd_ProjectRaster2 = baseflow)
#Rename fields in NURE dataset
data<-data %>%
rename(bfi48grd_ProjectRaster2 = baseflow)
#Rename fields in NURE dataset
rename(data, bfi48grd_ProjectRaster2 = baseflow)
data[,5]
View(data)
colnames(data[,5]) <- "baseflow"
colnames(data[,5]) <- 'baseflow'
?rename
#Rename fields in NURE dataset
rename(data[,5], bfi48grd_ProjectRaster2 = baseflow)
#Rename fields in NURE dataset
data %>%
rename(
bfi48grd_ProjectRaster2 = baseflow,
PRISM_ppt_30yr_ProjectRaster1, prism30yr
)
#Rename fields in NURE dataset
data %>%
rename(
baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1
)
library(tidyverse)
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data %>%
rename(
baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Load libraries
library(tidyverse)
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data %>%
rename(
baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Rename fields in NURE dataset
dataN<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth)
#Need to find missing fields then create new blank fields
d1ColNames<-colnames(data)
d2ColNames<-colnames(data2)
setdiff(a, b)
#Need to find missing fields then create new blank fields
a<-colnames(data)
b<-colnames(data2)
setdiff(a, b)
setdiff(b, a)
?setdiff
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality")
#Load libraries
library(tidyverse)
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth)
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteIDTest<-paste("nure-",data$rec_no, sep="")
View(data)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
summary(factor(data2$CharacteristicName))
c<-colnames(data3)
setdiff(a, c)
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb)
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(c, a)
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth
As = As_,
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth,
As = As_,
Fl = Fl_combined)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(c, a)
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb,
mutate(GENERALIZE_Metamorphic_gneiss = NA))
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb,
mutate(GENERALIZE_Metamorphic_gneiss = NA))
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb),
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NA)
View(data)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth,
As = As_,
Fl = Fl_combined)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss <- NA)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue)
#Rename fields in data from Saurav
data3<- data3 %>%
rename(welldpth = depth,
As = As_,
Fl = Fl_combined)
##Concatenate data source name to SiteID/WellID/Record Number
data$SiteID<-paste("nure-",data$rec_no, sep="")
data2$SiteID<-paste("nnWells-",data2$SiteID, sep="")
data3$SiteID<-paste("wtrQalPort-",data3$well_id, sep="")
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b)
View(data)
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2,
prism30yr = PRISM_ppt_30yr_ProjectRaster1,
U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NA)
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NA)
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NA)
View(data)
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NULL)
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = NULL)
View(data)
data$GENERALIZE_Metamorphic_gneiss
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss)
View(data)
data$GENERALIZE_Metamorphic_gneiss
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = 0)
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Clean_Nure6_Data_ExportTable.csv")
data2 <- read.csv("./01_arsenic/01_data/Cleaned_As_GIS_Filtered.csv")
data3 <- read.csv("./02_uranium/01_data/Clean_nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb) %>%
mutate(GENERALIZE_Metamorphic_gneiss = 0) %>%
mutate(GENERALIZE_Metamorphic_volcanic = 0)
View(data)
data$GENERALIZE_Metamorphic_volcanic
