#combine data sets
combined_data <- bind_rows(Nure, WQP)
combined_data1 <- bind_rows(combined_data, NNwells)#
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(Nure)
b<-colnames(WQP)
c<-colnames(NNwells)
setdiff(c, a)
setdiff(c, b)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b, shows what data is in a that is not in b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(c, b)
setdiff(c, a)
#Load libraries
library(reshape2)
library(dplyr)
library(tidyr)
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
getwd()
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
setwd("\\10.192.74.47\HooverShare\Shared_Group_Data")
setwd("//10.192.74.47/HooverShare/Shared_Group_Data")
setwd("/10.192.74.47/HooverShare/Shared_Group_Data")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Clean up the workspace
rm(list=ls())
#Load csv files
a<-read.csv("./02_Data/Raw_Data/WQP/00_archive/AZ_Uranium.csv", na.strings = "NULL")
b<-read.csv("./02_Data/Raw_Data/WQP/00_archive/NM_Uranium.csv", na.strings = "NULL")
c<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Ca.csv", na.strings = "NULL")
d<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Iron.csv", na.strings = "NULL")
e<-read.csv("./02_Data/Raw_Data/WQP/00_archive/ph.csv", na.strings = "NULL")
f<-read.csv("./02_Data/Raw_Data/WQP/00_archive/alkalinity.csv", na.strings = "NULL")
g<-read.csv("./02_Data/Raw_Data/WQP/00_archive/CO_Uranium.csv", na.strings = "NULL")
h<-read.csv("./02_Data/Raw_Data/WQP/00_archive/UT_Uranium.csv", na.strings = "NULL")
u<-rbind(a,b,g,h)
#Process uranium data (done)
u2 <- u %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(ResultMeasureMeasureUnitCode != "ratio") %>%
filter(CharacteristicName == "U")
summary(factor(u2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(u2$ResultMeasureMeasureUnitCode == "pCi/L") #Create an index with records that we need to convert
u2$ResultMeasureValue[mgL_indices] <- u2$ResultMeasureValue[mgL_indices] * 0.67 #Convert to pCi/L to ug/L match NN Wells analyte data
u2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units mg/L
#Calcium: keep mg/L (done)
c2 <- c %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved")
summary(factor(c2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(c2$ResultMeasureMeasureUnitCode == "ug/l" | c2$ResultMeasureMeasureUnitCode == "ug/L") #Create an index with records that we need to convert
c2$ResultMeasureValue[mgL_indices] <- c2$ResultMeasureValue[mgL_indices] / 1000 #Convert to mg/L to match NN Wells analyte data
c2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Iron: unit conversions (done)
d2 <- d %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(CharacteristicName == "Fe") #remove Ferric ion, Ferrous ion, and Iron-59
summary(factor(d2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(d2$ResultMeasureMeasureUnitCode == "mg/l" | d2$ResultMeasureMeasureUnitCode == "mg/L") #Create an index with records that we need to convert
d2$ResultMeasureValue[mgL_indices] <- d2$ResultMeasureValue[mgL_indices] * 1000 #Convert to ug/L to match NN Wells analyte data
d2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units ug/L
#pH - check that all measurements are in standard units (done)
e2 <- e %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Total")
#summary(factor(e2$ResultMeasureMeasureUnitCode))
#Alkalinity: convert ug/L to mg/L in ResultMeasureMeasureUnitCode (done)
f2 <- f %>%
drop_na(ResultMeasureMeasureUnitCode) %>%   #Remove rows with NA's using drop_na()
filter(ResultSampleFractionText == "Total") %>% #filter to total results since we want to use raw water samples
filter(CharacteristicName == "Alkalinity")
summary(factor(f2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(f2$ResultMeasureMeasureUnitCode == "ug/l") #Create an index with records that we need to convert
f2$ResultMeasureValue[mgL_indices] <- f2$ResultMeasureValue[mgL_indices] / 1000 #Convert to ug/L to match NN Wells analyte data
f2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Merge files
cdef<-rbind(c2,d2,e2,f2, u2)
cdef2 <- cdef %>%
filter(StateCode == 4 & (CountyCode == 1 | CountyCode == 5 | CountyCode == 7 | CountyCode == 15 | CountyCode == 17 | CountyCode == 25) |
(StateCode == 35 & (CountyCode == 3 | CountyCode ==6 | CountyCode ==31 | CountyCode ==39 | CountyCode ==43 | CountyCode ==45)) |
(StateCode == 08 & (CountyCode == 29 | CountyCode == 33 | CountyCode == 45 | CountyCode ==67 | CountyCode ==77 | CountyCode ==81 | CountyCode ==83 | CountyCode ==85 | CountyCode ==91 | CountyCode ==103 | CountyCode ==113)) |
(StateCode == 49 & (CountyCode == 1 | CountyCode == 7 | CountyCode ==13 | CountyCode ==15 | CountyCode ==17 | CountyCode == 19 | CountyCode ==21 | CountyCode ==23 | CountyCode ==25 | CountyCode ==27 | CountyCode ==31 | CountyCode == 37 | CountyCode ==39 | CountyCode ==41 | CountyCode ==47 | CountyCode ==49 | CountyCode ==51 | CountyCode == 53 | CountyCode ==55)))
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName+ResultMeasureMeasureUnitCode, value.var="ResultMeasureValue", median)
View(wide)
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName, value.var="ResultMeasureValue", median)
View(wide)
#Read GIS data from WQP
i<-read.csv("./02_Data/Raw_Data/WQP/00_archive/20241029_WQP_Export.csv", na.strings = "NULL")
View(i)
#Clean up new dataframe, drop worthless fields
cleani<- i [-c(2:25,27:79)]
View(cleani)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
View(WQP_All)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.y=TRUE)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
?distinct
#Return unique records
yourDataFrame <- i %>%
distinct(cleani .keep_all = TRUE)
#Return unique records
yourDataFrame <- i %>%
distinct(cleani, .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155])
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = FALSE)
#Return unique records
cleanNoDup<-distinct(cleani)
View(cleanNoDup)
#Return unique records
cleanNoDup<-distinct(cleani[,c(2:155)])
View(cleanNoDup)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleanNoDup, by="SiteID", all.x=TRUE)
View(WQP_All)
version()
version
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
AsTrain_x<-AsTrain[,-151]
AsTrain_y<-AsTrain[,151]
toys.vsurf <- VSURF(x = AsTrain_x, y = AsTrain_y, mtry = 54, parallel = TRUE, ncores = 16, clusterType = "FORK")
#Try variable tuning
library("VSURF")
toys.vsurf <- VSURF(x = AsTrain_x, y = AsTrain_y, mtry = 54, parallel = TRUE, ncores = 16, clusterType = "FORK")
summary(toys.vsurf)
plot(toys.vsurf)
toys.vsurf$varselect.interp
View(AsTrain_x)
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(2, 27, 97, 8, 13, 25, 151)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, ClassLTE10~., mtry=5, ntree=500, importance = TRUE);
print(model)
#
varImpPlot(model, sort=T, n.var= 6, main= "Variable Importance", pch=16)
impt<-data.frame(model$importance)
print(impt[order(impt$MeanDecreaseGini, decreasing = TRUE), ]   )
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE10)
confusion_mtx
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE10, positive ="1")
confusion_mtx
#Partial dependence plots to help us sort out the impact on an individual variable on As concentrations
partialPlot(model, AsTest, pH, "1", xlab="pH", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Cs, "1", xlab="Fe", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Cs, "1", xlab="A_Cs", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Hematite, "1", xlab="C_Hematite", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Be, "1", xlab="Top5_Be", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Ni, "1", xlab="Top5_Ni", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Calcite, "1", xlab="A_Calcite", ylab="As Class", lwd=4, col="green")
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, ClassLTE10~., mtry=54, ntree=500, importance = TRUE);
print(model)
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE10, positive ="1")
confusion_mtx
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
model<-randomForest(data=AsTrain, ClassLTE10~., mtry=54, ntree=500, importance = TRUE);
print(model)
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE10, positive ="1")
confusion_mtx
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
AsTrain_x<-AsTrain[,-151]
AsTrain_y<-AsTrain[,151]
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(2, 27, 97, 8, 13, 25, 151)]
length(AsTrain)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:length(AsTrain))) #Change to 1:7 if testing for real, 1:3 was used for model development
# Fitting Random Forest to the train dataset
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE10) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 5),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
classifier_RF
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, ClassLTE10~., mtry=1, ntree=500, importance = TRUE);
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:1-length(AsTrain))) #Change to 1:7 if testing for real, 1:3 was used for model development
View(tunegrid)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:1length(AsTrain))) #Change to 1:7 if testing for real, 1:3 was used for model development
View(tunegrid)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:length(AsTrain))) #Change to 1:7 if testing for real, 1:3 was used for model development
View(tunegrid)
# Fitting Random Forest to the train dataset
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE10) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 5),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:(length(AsTrain)-1)) #Change to 1:7 if testing for real, 1:3 was used for model development
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:(length(AsTrain)-1))) #Change to 1:7 if testing for real, 1:3 was used for model development
View(tunegrid)
# Fitting Random Forest to the train dataset
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE10) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 5),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
classifier_RF
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, ClassLTE10~., mtry=2, ntree=500, importance = TRUE);
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, factor(ClassLTE10)~., mtry=2, ntree=500, importance = TRUE);
print(model)
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE10, positive ="1")
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, factor(AsTest$ClassLTE10), positive ="1")
confusion_mtx
#Partial dependence plots to help us sort out the impact on an individual variable on As concentrations
partialPlot(model, AsTest, pH, "1", xlab="pH", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Cs, "1", xlab="A_Cs", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Hematite, "1", xlab="C_Hematite", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Be, "1", xlab="Top5_Be", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Ni, "1", xlab="Top5_Ni", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Calcite, "1", xlab="A_Calcite", ylab="As Class", lwd=4, col="green")
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#method indicates these variables(field indexes): 2, 27, 97, 8, 13, 25
#pH, A_Cs, C_Hematite, Top5_Be, Top5_Ni, A_Calcite
#Keep only useful precitors from variable selection step
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest, type = "probability")
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#method indicates these variables(field indexes): 2, 27, 97, 8, 13, 25
#pH, A_Cs, C_Hematite, Top5_Be, Top5_Ni, A_Calcite
#Keep only useful precitors from variable selection step
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
#Keep only useful precitors from variable selection step
AsTrain<-train[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,c(2, 27, 97, 8, 13, 25, 151)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
#method indicates these variables(field indexes): 2, 27, 97, 8, 13, 25
#pH, A_Cs, C_Hematite, Top5_Be, Top5_Ni, A_Calcite
#Keep only useful precitors from variable selection step
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(2, 27, 97, 8, 13, 25, 151)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, factor(ClassLTE10)~., mtry=2, ntree=500, importance = TRUE);
print(model)
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, factor(AsTest$ClassLTE10), positive ="1")
confusion_mtx
#Testing Data
xgbpred <- predict (model, AsTest, type="prob")
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y)) #keep this for reporting
AsTain_y<-AsTrain[,151]
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
AsTain_y<-AsTrain[,151]
AsTest_y<-AsTest[,151]
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
AsTrain_y<-AsTrain[,151]
AsTest_y<-AsTest[,151]
#method indicates these variables(field indexes): 2, 27, 97, 8, 13, 25
#pH, A_Cs, C_Hematite, Top5_Be, Top5_Ni, A_Calcite
#Keep only useful precitors from variable selection step
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(2, 27, 97, 8, 13, 25, 151)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, factor(ClassLTE10)~., mtry=2, ntree=500, importance = TRUE);
print(model)
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, factor(AsTest$ClassLTE10), positive ="1")
confusion_mtx
#Testing Data
rfpred <- predict (model, AsTest, type="prob")
#Testing Data
rfpred <- data.frame(predict (model, AsTest, type="prob"))
#Adjust the "true" threshold using Youden value
#For a figure
y_predJoin<-data.frame(cbind(AsTest_y, rfpred))#change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"PredNotexceed"
colnames(y_predJoin)[3]<-"PredExceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, PredExceed, Obsclass,
method = maximize_metric, metric = youden, pot_class = 1)
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
library(cutpointr)
cp <- cutpointr(y_predJoin, PredExceed, Obsclass,
method = maximize_metric, metric = youden, pot_class = 1)
summary(cp) #make note of the cutpoint value for comparision with lines 91-93 above
plot(cp)
#Extract ROC Curve data for plotting
a<-as.data.frame(cp$roc_curve)
a$sens<-a$tp/(a$tp+a$fn) #sensitivity
a$spec<-a$tn/(a$tn+a$fp) #specificity
a$j<-(a$tp/(a$tp+a$fn))+(a$tn/(a$tn+a$fp))-1 #j-index, also called Youden value
df <- a %>%
select(x.sorted, j, sens, spec) %>%
gather(key = "variable", value = "value", -x.sorted)
ggplot(df, aes(x = x.sorted, y = value)) +
geom_line(aes(color = variable, linetype = variable)) +
scale_color_manual(values = c("black","darkred", "steelblue")) +
xlab("As Detection Threshold - value above this threshold is considered a detection") + ylab("Metric Estimate")
#Load raster files for prediction model
wd <- ("/Users/hoover/desktop/")
rasterlist2 <-  list.files(paste0(wd,"spatialPredFormattedTifs"), full.names=TRUE, pattern=".tif$")
rasterlist2
d<-"/Users/hoover/desktop/spatialPredFormattedTifs/"
