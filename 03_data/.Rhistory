length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 0)
rep(0, times = 40)
rep(0, 1, 2), times = 10
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
?c()
?c
swirl()
num_vect(05, 55, -10, 6)
"num_vect"(0.5, 55, -10, 6)
numeric_vector
numeric_vector(0.5, 55, -10, 6)
numeric(0.5, 55, -10, 6)
c(0.5, 55, -10, 6)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- "My", "name, "is""
my_char <- "My" "name "is""
my_char <- "My" "name" "is"
my_char <- c("My, "name", "is)
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Aaron")
my_char
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", cep = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3), c("X", "Y", "Z") sep = " " )
paste(c1:3("X", "Y", "Z") sep = " " )
paste(c 1:3("X", "Y", "Z") sep = " " )
paste(c(1:3), c("X", "Y", "Z") sep = " ")
paste("c(1:3)"", "c("X", "Y", "Z")" sep = " ")
paste("c(1:3), "c("X", "Y", "Z")" sep = " ")
paste(1:3 c("X", "Y", "Z"))
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y,z), 100)
my_na <- is.na(NA)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na(TRUE))
sum("my_na"(TRUE))
my_na(sum(TRUE))
my_na
sum(my_na)
my_data
0/0
Inf- Inf
x
x[1:10]
x[is.na(x)]
y <- [!is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(1, 3, 4, 7)]
[c(3, 5, 7 )]
[c(3, 5, 7)]
x[c(3, 5, 7)]
x[0]
x[3000]
x[c(-2, -1)]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("food", "bar","norf")
names(vect2) <- c("foo", "bar","norf")
identical(vect, vect2 )
vect["bar"]
vect[c("foo", "bar")]
c <- a + b
a <- 4
b <- 1
c <- a + b
c <- a + b
c
a == b
??data.frame
View(ll)
swirl()
library(swirl)
swirl()
Sys.Date()
mean(c(2,4, 5))
submit()
boring_function('My first fuction!')
boring_function('My first function!')
boring_function
submit()
submit()
submit()
my_mean(c(4, 5, 10))
submit()
submit()
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
submit()
submit()
submit()
submit()
evaluate(stdev, c(1.4, 3.6, 7.9, 8.8))
evaluate(standarddeviatio , c(1.4, 3.6, 7.9, 8.8))
evaluate(standarddeviation , c(1.4, 3.6, 7.9, 8.8))
evaluate(std, c(1.4, 3.6, 7.9, 8.8))
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x){x+1}, c(8, 4, 0))
evaluate(function(x), c(8, 4, 0))
evaluate(function(x){x[1]}, c(8, 4, 0))
evaluate(function(x){x[3]}, c(8, 4, 0))
evaluate(function(x){x[length(3)]}, c(8, 4, 0))
evaluate(function(x){x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
submit()
paste(good day)
paste("good day")
paste("Good", "day")
telegram("Good", "day")
submit()
submit()
submit()
mad_libs(glendale, tall, doors)
mad_libs("glendale", "tall", "doors")
submit()
submit()
submit()
%p%("I", "love", "R")
"I" %p% "love" %p% "R!"
head(flags)
dim(flags)
viewinfo()
class(flags)
cls_lists <- lapply(flags,class)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
?'$'
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, rang)
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(flags, unique)
lapply(flags, length)
info()
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function (elem) elem[2])
#setwd("~/Desktop")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality")
#Load libraries
library(tidyverse)
library(dplyr)
#Clean up the workspace
rm(list=ls())
#Load data
data <- read.csv("./02_uranium/01_data/Nure7_Data_ExportTable.csv")
data2 <- read.csv("./02_uranium/01_data/wqpData_cleaned_20240808.csv", na.strings = "NULL")
data3 <- read.csv("./02_uranium/01_data/nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
data<- data %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb)
#Rename fields in NN Wells Data
data2<- data2 %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue,
F30mElevationFoCo = F30mElevat)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(data)
b<-colnames(data2)
c<-colnames(data3)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(a, c)
#setwd("~/Desktop")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality")
#Load libraries
library(tidyverse)
library(dplyr)
#Clean up the workspace
rm(list=ls())
#Load data
Nure <- read.csv("./02_uranium/01_data/Nure7_Data_ExportTable.csv")
WQP <- read.csv("./02_uranium/01_data/wqpData_cleaned_20240808.csv", na.strings = "NULL")
NNwells <- read.csv("./02_uranium/01_data/nnwells3_ExportTable.csv")
#Rename fields in NURE dataset
Nure <- Nure %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb)
#Rename fields in WQP Data
WQP<- WQP %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue,
F30mElevationFoCo = F30mElevat)
#Rename fields in NNwells data
NNwells<- NNwells %>%
rename(welldpth = depth,
As = As_,
Fl = Fl_combine)
#table(data3$Fl)
##Concatenate data source name to SiteID/WellID/Record Number
Nure$SiteID<-paste("nure-",Nure$rec_no, sep="")
WQP$SiteID<-paste("nnWells-",WQP$SiteID, sep="")
NNwells$SiteID<-paste("wtrQalPort-",NNwells$well_id, sep="")
str(data3$SiteID)
str(NNwells$SiteID)
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(Nure)
b<-colnames(WQP)
c<-colnames(NNwells)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(c, b)
#setwd("~/Desktop")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality")
#Load libraries
library(tidyverse)
library(dplyr)
#Clean up the workspace
rm(list=ls())
#Load data
Nure <- read.csv("./02_uranium/01_data/Nure7_Data_ExportTable.csv")
WQP <- read.csv("./02_uranium/01_data/wqpData_cleaned_20240808.csv", na.strings = "NULL")
NNwells <- read.csv("./02_uranium/01_data/nnwells3_Check_ExportTable.csv")
#Rename fields in NURE dataset
Nure <- Nure %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb)
#Rename fields in WQP Data
WQP<- WQP %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue,
F30mElevationFoCo = F30mElevat)
#str(NNwells$SiteID)
#combine data sets
combined_data <- bind_rows(Nure, WQP)
combined_data1 <- bind_rows(combined_data, NNwells)#
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(Nure)
b<-colnames(WQP)
c<-colnames(NNwells)
setdiff(c, a)
setdiff(c, b)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b, shows what data is in a that is not in b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(c, b)
setdiff(c, a)
#Load libraries
library(reshape2)
library(dplyr)
library(tidyr)
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
getwd()
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
setwd("\\10.192.74.47\HooverShare\Shared_Group_Data")
setwd("//10.192.74.47/HooverShare/Shared_Group_Data")
setwd("/10.192.74.47/HooverShare/Shared_Group_Data")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Clean up the workspace
rm(list=ls())
#Load csv files
a<-read.csv("./02_Data/Raw_Data/WQP/00_archive/AZ_Uranium.csv", na.strings = "NULL")
b<-read.csv("./02_Data/Raw_Data/WQP/00_archive/NM_Uranium.csv", na.strings = "NULL")
c<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Ca.csv", na.strings = "NULL")
d<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Iron.csv", na.strings = "NULL")
e<-read.csv("./02_Data/Raw_Data/WQP/00_archive/ph.csv", na.strings = "NULL")
f<-read.csv("./02_Data/Raw_Data/WQP/00_archive/alkalinity.csv", na.strings = "NULL")
g<-read.csv("./02_Data/Raw_Data/WQP/00_archive/CO_Uranium.csv", na.strings = "NULL")
h<-read.csv("./02_Data/Raw_Data/WQP/00_archive/UT_Uranium.csv", na.strings = "NULL")
u<-rbind(a,b,g,h)
#Process uranium data (done)
u2 <- u %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(ResultMeasureMeasureUnitCode != "ratio") %>%
filter(CharacteristicName == "U")
summary(factor(u2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(u2$ResultMeasureMeasureUnitCode == "pCi/L") #Create an index with records that we need to convert
u2$ResultMeasureValue[mgL_indices] <- u2$ResultMeasureValue[mgL_indices] * 0.67 #Convert to pCi/L to ug/L match NN Wells analyte data
u2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units mg/L
#Calcium: keep mg/L (done)
c2 <- c %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved")
summary(factor(c2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(c2$ResultMeasureMeasureUnitCode == "ug/l" | c2$ResultMeasureMeasureUnitCode == "ug/L") #Create an index with records that we need to convert
c2$ResultMeasureValue[mgL_indices] <- c2$ResultMeasureValue[mgL_indices] / 1000 #Convert to mg/L to match NN Wells analyte data
c2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Iron: unit conversions (done)
d2 <- d %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(CharacteristicName == "Fe") #remove Ferric ion, Ferrous ion, and Iron-59
summary(factor(d2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(d2$ResultMeasureMeasureUnitCode == "mg/l" | d2$ResultMeasureMeasureUnitCode == "mg/L") #Create an index with records that we need to convert
d2$ResultMeasureValue[mgL_indices] <- d2$ResultMeasureValue[mgL_indices] * 1000 #Convert to ug/L to match NN Wells analyte data
d2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units ug/L
#pH - check that all measurements are in standard units (done)
e2 <- e %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Total")
#summary(factor(e2$ResultMeasureMeasureUnitCode))
#Alkalinity: convert ug/L to mg/L in ResultMeasureMeasureUnitCode (done)
f2 <- f %>%
drop_na(ResultMeasureMeasureUnitCode) %>%   #Remove rows with NA's using drop_na()
filter(ResultSampleFractionText == "Total") %>% #filter to total results since we want to use raw water samples
filter(CharacteristicName == "Alkalinity")
summary(factor(f2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(f2$ResultMeasureMeasureUnitCode == "ug/l") #Create an index with records that we need to convert
f2$ResultMeasureValue[mgL_indices] <- f2$ResultMeasureValue[mgL_indices] / 1000 #Convert to ug/L to match NN Wells analyte data
f2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Merge files
cdef<-rbind(c2,d2,e2,f2, u2)
cdef2 <- cdef %>%
filter(StateCode == 4 & (CountyCode == 1 | CountyCode == 5 | CountyCode == 7 | CountyCode == 15 | CountyCode == 17 | CountyCode == 25) |
(StateCode == 35 & (CountyCode == 3 | CountyCode ==6 | CountyCode ==31 | CountyCode ==39 | CountyCode ==43 | CountyCode ==45)) |
(StateCode == 08 & (CountyCode == 29 | CountyCode == 33 | CountyCode == 45 | CountyCode ==67 | CountyCode ==77 | CountyCode ==81 | CountyCode ==83 | CountyCode ==85 | CountyCode ==91 | CountyCode ==103 | CountyCode ==113)) |
(StateCode == 49 & (CountyCode == 1 | CountyCode == 7 | CountyCode ==13 | CountyCode ==15 | CountyCode ==17 | CountyCode == 19 | CountyCode ==21 | CountyCode ==23 | CountyCode ==25 | CountyCode ==27 | CountyCode ==31 | CountyCode == 37 | CountyCode ==39 | CountyCode ==41 | CountyCode ==47 | CountyCode ==49 | CountyCode ==51 | CountyCode == 53 | CountyCode ==55)))
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName+ResultMeasureMeasureUnitCode, value.var="ResultMeasureValue", median)
View(wide)
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName, value.var="ResultMeasureValue", median)
View(wide)
#Read GIS data from WQP
i<-read.csv("./02_Data/Raw_Data/WQP/00_archive/20241029_WQP_Export.csv", na.strings = "NULL")
View(i)
#Clean up new dataframe, drop worthless fields
cleani<- i [-c(2:25,27:79)]
View(cleani)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
View(WQP_All)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.y=TRUE)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
?distinct
#Return unique records
yourDataFrame <- i %>%
distinct(cleani .keep_all = TRUE)
#Return unique records
yourDataFrame <- i %>%
distinct(cleani, .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155])
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = FALSE)
#Return unique records
cleanNoDup<-distinct(cleani)
View(cleanNoDup)
#Return unique records
cleanNoDup<-distinct(cleani[,c(2:155)])
View(cleanNoDup)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleanNoDup, by="SiteID", all.x=TRUE)
View(WQP_All)
version()
version
# SETUP
#Load and install packages
library(caTools)
library(randomForest)
library(caret)
#library(tidyverse)
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
setwd("/Users/hoover/Downloads")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE2_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE2_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157, 159:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157, 159:168)]
#Ensure ClassLTE2 is a Factor (Categorical Variable)
AsTrain$ClassLTE2 <- as.factor(AsTrain$ClassLTE2)
AsTest$ClassLTE2  <- as.factor(AsTest$ClassLTE2)
#setwd("/Users/hoover/Downloads")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE2_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE2_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157, 159:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157, 159:168)]
#Ensure ClassLTE2 is a Factor (Categorical Variable)
AsTrain$ClassLTE2 <- as.factor(AsTrain$ClassLTE2)
AsTest$ClassLTE2  <- as.factor(AsTest$ClassLTE2)
#Load data
classifier_RF <- readRDS("2025-01-31_rf.rds")
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-06_rf_10ugL.rds")
classifier_RF
classifier_RF$modelInfo$parameters
classifier_RF$modelInfo$oob()
classifier_RF$finalModel$importance
str(classifier_RF$finalModel$importance)
classifier_RF$finalModel$importance[[1]]
classifier_RF$finalModel$importance[1]
classifier_RF$finalModel$importance[2]
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-06_rf_5ugL.rds")
classifier_RF
classifier_RF$finalModel$importance
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-06_rf_5ugL.rds")
classifier_RF
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-05_rf_5ugL.rds")
classifier_RF
str(classifier_RF$finalModel$importance)
classifier_RF$finalModel$importance
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-06_rf_5ugL.rds")
classifier_RF$finalModel$importance
#Load data
classifier_RF <- readRDS("./RF_rds/2025-02-06_rf_10ugL.rds")
classifier_RF$finalModel$importance
