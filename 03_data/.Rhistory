<<<<<<< HEAD
dir.create(testdir2) file.path("testdir3")
dir.create(testdir2), file.path("testdir3")
dir.create(testdir2)
dir.create("testdir2")
dir.create(file.path('testdir2, 'testdir3), recursive = TRUE)
dir.create(file.path('testdir2', 'testdir3'), recursive = TRUE)
setwd()
setwd(old.dir)
unlink(x = "testdir/", recursive = TRUE)
swirl()
1:20
pi:10
15:1
?`:`
seq(1,20)
seq(0, 10, by=0.5)
my_seq <- seq(5, 10, length=30)
length(my_seq)
1:length(my_seq)
seq(along.with = my_seq)
seq_along(my_seq)
rep(0, times = 0)
rep(0, times = 40)
rep(0, 1, 2), times = 10
rep(c(0, 1, 2), times = 10)
rep(c(0, 1, 2), each = 10)
?c()
?c
swirl()
num_vect(05, 55, -10, 6)
"num_vect"(0.5, 55, -10, 6)
numeric_vector
numeric_vector(0.5, 55, -10, 6)
numeric(0.5, 55, -10, 6)
c(0.5, 55, -10, 6)
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- "My", "name, "is""
my_char <- "My" "name "is""
my_char <- "My" "name" "is"
my_char <- c("My, "name", "is)
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Aaron")
my_char
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", cep = " ")
paste("Hello", "world!", sep = " ")
paste(c(1:3), c("X", "Y", "Z") sep = " " )
paste(c1:3("X", "Y", "Z") sep = " " )
paste(c 1:3("X", "Y", "Z") sep = " " )
paste(c(1:3), c("X", "Y", "Z") sep = " ")
paste("c(1:3)"", "c("X", "Y", "Z")" sep = " ")
paste("c(1:3), "c("X", "Y", "Z")" sep = " ")
paste(1:3 c("X", "Y", "Z"))
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y,z), 100)
my_na <- is.na(NA)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na(TRUE))
sum("my_na"(TRUE))
my_na(sum(TRUE))
my_na
sum(my_na)
my_data
0/0
Inf- Inf
x
x[1:10]
x[is.na(x)]
y <- [!is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(1, 3, 4, 7)]
[c(3, 5, 7 )]
[c(3, 5, 7)]
x[c(3, 5, 7)]
x[0]
x[3000]
x[c(-2, -1)]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo = 11, bar = 2, norf = NA)
vect
names(vect)
vect2 <- c(11, 2, NA)
names(vect2) <- c("food", "bar","norf")
names(vect2) <- c("foo", "bar","norf")
identical(vect, vect2 )
vect["bar"]
vect[c("foo", "bar")]
c <- a + b
a <- 4
b <- 1
c <- a + b
c <- a + b
c
a == b
??data.frame
View(ll)
swirl()
library(swirl)
swirl()
Sys.Date()
mean(c(2,4, 5))
submit()
boring_function('My first fuction!')
boring_function('My first function!')
boring_function
submit()
submit()
submit()
my_mean(c(4, 5, 10))
submit()
submit()
remainder(5)
remainder(11, 5)
remainder(divisor = 11, num = 5)
remainder(4, div = 2)
args(remainder)
submit()
submit()
submit()
submit()
submit()
evaluate(stdev, c(1.4, 3.6, 7.9, 8.8))
evaluate(standarddeviatio , c(1.4, 3.6, 7.9, 8.8))
evaluate(standarddeviation , c(1.4, 3.6, 7.9, 8.8))
evaluate(std, c(1.4, 3.6, 7.9, 8.8))
evaluate(sd, c(1.4, 3.6, 7.9, 8.8))
evaluate(function(x){x+1}, 6)
evaluate(function(x){x+1}, c(8, 4, 0))
evaluate(function(x), c(8, 4, 0))
evaluate(function(x){x[1]}, c(8, 4, 0))
evaluate(function(x){x[3]}, c(8, 4, 0))
evaluate(function(x){x[length(3)]}, c(8, 4, 0))
evaluate(function(x){x[length(x)]}, c(8, 4, 0))
?paste
paste("Programming", "is", "fun!")
submit()
paste(good day)
paste("good day")
paste("Good", "day")
telegram("Good", "day")
submit()
submit()
submit()
mad_libs(glendale, tall, doors)
mad_libs("glendale", "tall", "doors")
submit()
submit()
submit()
%p%("I", "love", "R")
"I" %p% "love" %p% "R!"
head(flags)
dim(flags)
viewinfo()
class(flags)
cls_lists <- lapply(flags,class)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
?'$'
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
lapply(flag_shapes, rang)
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6, 6))
unique_vals <- lapply(flags, unique)
unique_vals
lapply(flags, unique)
lapply(flags, length)
info()
sapply(unique_vals, length)
sapply(flags, unique)
lapply(unique_vals, function (elem) elem[2])
#Load libraries
library(reshape2)
library(dplyr)
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Load csv files
a<-read.csv("./02_Data/Raw_Data/WQP/00_archive/AZ_Uranium.csv")
b<-read.csv("./02_Data/Raw_Data/WQP/00_archive/NM_Uranium.csv")
c<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Ca.csv", na.strings = "NULL")
d<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Iron.csv", na.strings = "NULL")
e<-read.csv("./02_Data/Raw_Data/WQP/00_archive/ph.csv", na.strings = "NULL")
f<-read.csv("./02_Data/Raw_Data/WQP/00_archive/alkalinity.csv", na.strings = "NULL")
#Process the files
filter(ResultSampleFractionText == "Total") %>%
gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode)))
gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
#for alkalinity and pH: check activity media name is water, check result sample fraction text to be "total", check result measure measure unit code is "std units", if anything else drop it
gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
#Process the files
f2<- f %>%
mutate() %>%
#for alkalinity and pH: check activity media name is water, check result sample fraction text to be "total", check result measure measure unit code is "std units", if anything else drop it
f<-read.csv("./02_Data/Raw_Data/WQP/00_archive/alkalinity.csv", na.strings = "NULL")
#Process the files
f2<- f %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
f3 <- gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
f3 <- f2 gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
f3 <- gsub("NULL"", as.character(f$ResultMeasureMeasureUnitCode))
f3 <- gsub("NULL"", as.character(f2$ResultMeasureMeasureUnitCode))
#Process the files
f2 <- f %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
f3 <- gsub("NULL"", as.character(f2$ResultMeasureMeasureUnitCode))
#for alkalinity and pH: check activity media name is water, check result sample fraction text to be "total", check result measure measure unit code is "std units", if anything else drop it
f3 <- gsub("NULL"", as.character(f2$ResultMeasureMeasureUnitCode))
#Alkalinity
f2 <- f %>%
filter(ResultSampleFractionText == "Total") %>%
#Alkalinity
f2 <- f %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
f3 <- f2 %>% filter(ResultMeasureMeasureUnitCode != "NULL")
View(f3)
write.csv(f3, "alkalinitycheck.csv", row.names = FALSE)
write.csv(f3, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
f3 <- f2 %>% filter(ResultMeasureMeasureUnitCode != "NULL")
ug_to_mg <-0.001
f4 <- f3 %>%
mutate(ResultMeasureMeasureUnitCode = ifelse(Unit == "ug/L", ResultMeasureMeasureUnitCode * ug_to_mg, ResultMeasureMeasureUnitCode),
ResultMeasureValue = ifelse(ResultMeasureValue == "ug/L", "mg/L", ResultMeasureValue))
f4 <- f3 %>%
mutate(ResultMeasureMeasureUnitCode = ifelse(ResultMeasureValue == "ug/L", ResultMeasureMeasureUnitCode * ug_to_mg, ResultMeasureMeasureUnitCode),
ResultMeasureValue = ifelse(ResultMeasureValue == "ug/L", "mg/L", ResultMeasureValue))
write.csv(f4, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
write.csv(f4, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
mutate()
mutate
#Alkalinity
f2 <- f %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
f3 <- f2 %>% filter(ResultMeasureMeasureUnitCode != "NULL")
#f4 <- f3 %>%
#  mutate(ResultMeasureMeasureUnitCode = ifelse(ResultMeasureValue == "ug/L", ResultMeasureMeasureUnitCode * ug_to_mg, ResultMeasureMeasureUnitCode),
#         ResultMeasureValue = ifelse(ResultMeasureValue == "ug/L", "mg/L", ResultMeasureValue))
write.csv(f3, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
ug_to_mg <-0.001
f4 <- f3 %>%
mutate(ResultMeasureMeasureUnitCode = ifelse(ResultMeasureValue == "ug/L", ResultMeasureMeasureUnitCode * ug_to_mg, ResultMeasureMeasureUnitCode),
ResultMeasureValue = ifelse(ResultMeasureValue == "ug/L", "mg/L", ResultMeasureValue))
write.csv(f4, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
write.csv(f4, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
f3 <- f2 %>% filter(ResultMeasureMeasureUnitCode != "NULL")
ug_to_mg <-0.001
f4 <- f3 %>%
ResultMeasureValue = ifelse(ResultMeasureMeasureUnitCode == "ug/L", ResultMeasureValue * ug_to_mg, ResultMeasureValue),  # Convert values
f4 <- f3 %>%
ResultMeasureValue = ifelse(ResultMeasureMeasureUnitCode == "ug/L", ResultMeasureValue * ug_to_mg, ResultMeasureValue)  # Convert values
write.csv(f4, file = "~/Desktop/alkalinitycheck.csv", row.names = FALSE)
write.csv(e3, file = "~/Desktop/pHcheck.csv", row.names = FALSE)
#pH
e2 <- e %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
e3 <- e2 %>% filter(ResultMeasureMeasureUnitCode != "NULL")
write.csv(e3, file = "~/Desktop/pHcheck.csv", row.names = FALSE)
#Iron
d2 <- d %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
write.csv(d2, file = "~/Desktop/pHcheck.csv", row.names = FALSE)
#Calcium: filter to only dissolved in ResultSampleFractionText, keep mg/L (need to do)
c2 <- c %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
write.csv(c2, file = "~/Desktop/ironcheck.csv", row.names = FALSE)
write.csv(c2, file = "~/Desktop/calciumcheck.csv", row.names = FALSE)
#Calcium: filter to only dissolved in ResultSampleFractionText, keep mg/L (need to do)
c2 <- c %>%
filter(ResultSampleFractionText == "Total") %>%
mutate()
write.csv(c2, file = "~/Desktop/calciumcheck.csv", row.names = FALSE)
#Calcium: filter to only dissolved in ResultSampleFractionText, keep mg/L (need to do)
c2 <- c %>%
filter(ResultSampleFractionText == "Dissolved") %>%
mutate()
write.csv(c2, file = "~/Desktop/calciumcheck.csv", row.names = FALSE)
write.csv(c2, file = "~/Desktop/calciumcheck.csv", row.names = FALSE)
write.csv(a, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
write.csv(b, file = "~/Desktop/NM_Ucheck.csv", row.names = FALSE)
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a filter(CharacteristicName == "Uranium-238" |
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
b2 <- b %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
write.csv(a2, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
write.csv(b2, file = "~/Desktop/NM_Ucheck.csv", row.names = FALSE)
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U" |
ResultMeasureValue != "NULL") %>%
mutate()
write.csv(a2, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U" |
ResultMeasureValue != "NULL") %>%
mutate()
write.csv(a2, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
b2 <- b %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
write.csv(b2, file = "~/Desktop/NM_Ucheck.csv", row.names = FALSE)
write.csv(a2, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U" |) %>%
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
a3 <- a2 %>% filter(ResultMeasureValue != "NULL")
b2 <- b %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
b3 <- b2 %>% filter(ResultMeasureValue != "NULL")
write.csv(a2, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
write.csv(b2, file = "~/Desktop/NM_Ucheck.csv", row.names = FALSE)
#Uranium: AZ (keep "U" and "Uranium-238" in CharacteristicName), NM (keep "U" and "Uranium-238" in CharacteristicName)
a2 <- a %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
a3 <- a2 %>% filter(ResultMeasureValue != "NULL")
b2 <- b %>%
filter(CharacteristicName == "Uranium-238" |
CharacteristicName == "U") %>%
mutate()
b3 <- b2 %>% filter(ResultMeasureValue != "NULL")
write.csv(a3, file = "~/Desktop/AZ_Ucheck.csv", row.names = FALSE)
write.csv(b3, file = "~/Desktop/NM_Ucheck.csv", row.names = FALSE)
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Clean up the workspace
rm(list=ls())
WQP <- read.csv(a<-read.csv("./02_Data/Raw_Data/WQP_As_All.csv", na.strings = "NULL")
As_COPLat_Data<-rbind(WQP, NNWells)
WQP <- read.csv("./02_Data/Raw_Data/WQP_As_All.csv", na.strings = "NULL")
NNWells <- read.csv("./02_Data/Raw_Data/Clean_nnwells3_ExportTable.csv", na.strings = "NULL")
As_COPLat_Data<-rbind(WQP, NNWells)
library(reshape2)
library(gtools)
library(dplyr)
library(tidyr)
library(ggcorrplot)
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:159, 161:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:159, 161:168)]
AsTrain_y<-AsTrain[,151]
AsTest_y<-AsTest[,151]
#Keep only useful predictors from variable selection step
AsTrain<-AsTrain[,c(25, 2, 3, 105, 1, 104, 9, 97, 36, 58, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(25, 2, 3, 105, 1, 104, 9, 97, 36, 58, 151)]
#Ensure ClassLTE5 is a Factor (Categorical Variable)
AsTrain$ClassLTE5 <- as.factor(AsTrain$ClassLTE5)
AsTest$ClassLTE5  <- as.factor(AsTest$ClassLTE5)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, factor(ClassLTE5)~., mtry=116, ntree=500, importance = TRUE);
print(model)
#Partial dependence plots to help us sort out the impact on an individual variable on As concentrations
partialPlot(model, AsTest, A_Calcite, "1", xlab="A_Calcite", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, pH, "1", xlab="pH", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, prism30yr, "1", xlab="prism30yr", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Tot_K_fs, "1", xlab="C_Tot_K_fs", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Fe, "1", xlab="Fe", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Tot_14A, "1", xlab="C_Tot_14A", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Ca, "1", xlab="Top5_Ca", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Hematite, "1", xlab="C_Hematite", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Kaolinit, "1", xlab="A_Kaolinit", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Tot_Flds, "1", xlab="A_Tot_Flds", ylab="As Class", lwd=4, col="green")
# Predicting the Test set results
y_pred <- predict(model, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, factor(AsTest$ClassLTE5), positive ="1")
confusion_mtx
#Testing Data
rfpred <- data.frame(predict (model, AsTest, type="prob"))
#Adjust the "true" threshold using Youden value
#For a figure
y_predJoin<-data.frame(cbind(AsTest_y, rfpred))#change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"PredNotexceed"
colnames(y_predJoin)[3]<-"PredExceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
library(cutpointr)
cp <- cutpointr(y_predJoin, PredExceed, Obsclass,
method = maximize_metric, metric = youden, pot_class = 1)
summary(cp) #make note of the cutpoint value for comparison with lines 91-93 above
plot(cp)
#Extract ROC Curve data for plotting
a<-as.data.frame(cp$roc_curve)
a$sens<-a$tp/(a$tp+a$fn) #sensitivity
a$spec<-a$tn/(a$tn+a$fp) #specificity
a$j<-(a$tp/(a$tp+a$fn))+(a$tn/(a$tn+a$fp))-1 #j-index, also called Youden value
##Make a plot like USGS PFAS paper S8
library(tidyverse)
df <- a %>%
select(x.sorted, j, sens, spec) %>%
gather(key = "variable", value = "value", -x.sorted)
ggplot(df, aes(x = x.sorted, y = value)) +
geom_line(aes(color = variable, linetype = variable)) +
scale_color_manual(values = c("black","darkred", "steelblue")) +
xlab("As Detection Threshold - value above this threshold is considered a detection") + ylab("Metric Estimate")
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
=======
library(caTools)
library(caret)
library(gbm)
library(xgboost) # for xgboost
library("SHAPforxgboost")
library(data.table)
library(cutpointr)
#library(tidyverse)
#for spatial data
library(raster)
library(sp)
>>>>>>> 76459b16812439ad6e7f523698b2762a5d84ea57
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
<<<<<<< HEAD
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
AsTrain_y<-AsTrain[,151]
AsTest_y<-AsTest[,151]
#Keep only useful precitors from variable selection step
AsTrain<-AsTrain[,c(2, 27, 97, 8, 13, 25, 151)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-AsTest[,c(2, 27, 97, 8, 13, 25, 151)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE10 <- as.factor(AsTrain$ClassLTE10)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
#Run random forest model
#mtry is from step 1, might want to try different number of trees too
model<-randomForest(data=AsTrain, factor(ClassLTE10)~., mtry=2, ntree=500, importance = TRUE);
print(model)
#Partial dependence plots to help us sort out the impact on an individual variable on As concentrations
partialPlot(model, AsTest, pH, "1", xlab="pH", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Cs, "1", xlab="A_Cs", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, C_Hematite, "1", xlab="C_Hematite", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Be, "1", xlab="Top5_Be", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, Top5_Ni, "1", xlab="Top5_Ni", ylab="As Class", lwd=4, col="green")
partialPlot(model, AsTest, A_Calcite, "1", xlab="A_Calcite", ylab="As Class", lwd=4, col="green")
=======
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Testing Data
xgbpred <- predict (model, xgb_test)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Make a list of the fewest number of variables with the highest overall prediction accuracy
a<-list("pH", "prism30yr", "A_Cs", "A_Aragon", "C_Hematite", "Fe", "Top5_S", "C_Cr", "A_Calcite",
"DepthToGW", "C_Mo", "Top5_Ca", "A_Tot_14A", "C_Amorph", "C_Analcime")
#define predictor and response variables in training set, As= 10 ug/L, keep variables defined above
train_x = data.matrix(train[, c(3, 5, 29, 25, 99, 2, 17, 71, 27, 108, 80, 11, 58, 65, 66)])
train_y = train[,161]
#define predictor and response variables in testing set
test_x = data.matrix(test[, c(3, 5, 29, 25, 99, 2, 17, 71, 27, 108, 80, 11, 58, 65, 66)])
test_y = test[,161]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Set parameters from all the tuning, steps 2 and 3
params = list(alpha = 2,
lambda = 5,
gamma = 1,
max_delta_step = 1,
eta = 0.005,
max_depth = 6,
subsample = 0.50,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
#Fully tuned model
model = xgboost(data = xgb_train, params = params,
nrounds = 750, objective = "binary:logistic",
eval_metric = "error", verbose = 1,
print_every_n = 100)
#Testing Data
xgbpred <- predict (model, xgb_test)
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y)) #keep this for reporting
#Load raster files for prediction model
wd <- ("/Users/hoover/desktop/")
#wd <- ("/Users/aaronnuanez/desktop/")
rasterlist2 <-  list.files(paste0(wd,"spatialPredFormattedTifs"), full.names=TRUE, pattern=".tif$")
rasterlist2
#d<-"/Users/hoover/desktop/spatialPredFormattedTifs/"
d<-"/Users/aaronnuanez/desktop/spatialPredFormattedTifs/"
#library(terra)
#Load each raster to check extent and crop as needed
A_Aragon<-raster(paste(d, "A_Aragon.tif", sep=""))
d<-"/Users/hoover/desktop/spatialPredFormattedTifs/"
#d<-"/Users/aaronnuanez/desktop/spatialPredFormattedTifs/"
#library(terra)
#Load each raster to check extent and crop as needed
A_Aragon<-raster(paste(d, "A_Aragon.tif", sep=""))
A_Calcite<-raster(paste(d,"A_Calcite.tif", sep=""))
A_Cs<-raster(paste(d,"A_Cs.tif", sep=""))
A_Tot_14A<-raster(paste(d,"A_Tot_14A.tif", sep=""))
C_Amorph<-raster(paste(d,"C_Amorph.tif", sep=""))
C_Analcime<-raster(paste(d,"C_Analcime.tif", sep=""))
C_Cr<-raster(paste(d,"C_Cr.tif", sep=""))
C_Hematite<-raster(paste(d,"C_Hematite.tif", sep=""))
C_Mo<-raster(paste(d,"C_Mo.tif", sep=""))
Fe<-raster(paste(d,"Fe.tif", sep=""))
pH<-raster(paste(d,"pH.tif", sep=""))
prism30yr<-raster(paste(d,"prism30yr.tif", sep=""))
Top5_Ca<-raster(paste(d,"Top5_Ca.tif", sep=""))
Top5_S<-raster(paste(d,"Top5_S.tif", sep=""))
DepthToGW<-raster(paste(d,"DepthToGW.tif", sep=""))
#Change names so they match the XGB model
A_Aragon@data@names<-"A_Aragon"
A_Calcite@data@names<-"A_Calcite"
A_Cs@data@names<-"A_Cs"
A_Tot_14A@data@names<-"A_Tot_14A"
C_Amorph@data@names<-"C_Amorph"
C_Analcime@data@names<-"C_Analcime"
C_Cr@data@names<-"C_Cr"
C_Hematite@data@names<-"C_Hematite"
C_Mo@data@names<-"C_Mo"
Fe@data@names<-"Fe"
pH@data@names<-"pH"
prism30yr@data@names<-"prism30yr"
Top5_Ca@data@names<-"Top5_Ca"
Top5_S@data@names<-"Top5_S"
DepthToGW@data@names<-"DepthToGW"
# create raster stack and convert to a maxtrix so it works with predict function for XGB
rstack1 <- stack(pH, prism30yr, A_Cs, A_Aragon, C_Hematite, Fe, Top5_S,
C_Cr, A_Calcite, DepthToGW, C_Mo, Top5_Ca, A_Tot_14A,
C_Amorph,C_Analcime)
rstack2<-rasterToPoints(rstack1)
# To prepare the long-format data:
shap_long <- shap.prep(xgb_model = model, X_train = train_x)
# **SHAP summary plot**
shap.plot.summary(shap_long)
>>>>>>> 76459b16812439ad6e7f523698b2762a5d84ea57
