setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(c, b)
#setwd("~/Desktop")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality")
#Load libraries
library(tidyverse)
<<<<<<< HEAD
#install.packages("cutpointr") #install only once then comment out
library(cutpointr)
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ]
#Drop unused fields
trainAs<-train[,-c(1, 4, 109:112, 157:160, 162:168)] #Drop the As concentration, and the categorical variables we already transformed
testAs<-test[,-c(1, 4, 109:112, 157:160, 162:168)]
#Load XGB model
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-08_ClassLTE1_cv10_xgb.rds")
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-04_ClassLTE2_cv10_xgb.rds")
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-05_ClassLTE3_cv10_xgb.rds")
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-05_ClassLTE5_cv10_xgb.rds")
Arsenic_xgb<-readRDS("./XGB_rds/2024-12-19_ClassLTE10_cv10_g0_xgb.rds")
Arsenic_xgb
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
# Filter data into train and test sets based on logical variable 'trainCat2'
#train <- Asdata[Asdata$trainClassLTE2_splt == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#test <- Asdata[Asdata$trainClassLTE1_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#test <- Asdata[Asdata$trainClassLTE2_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#test <- Asdata[Asdata$trainClassLTE3_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
#rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
#AsTrain<-train[,-c(1, 4, 109:112, 157, 159:168)] #Drop the As concentration, and the categorical variables we already transformed
#AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)] #for use with LTE1
#AsTest<-test[,-c(1, 4, 109:112, 157,159:168)] #for use with LTE2
#AsTest<-test[,-c(1, 4, 109:112, 157:158, 160:168)] #for use with LTE3
#AsTest<-test[,-c(1, 4, 109:112, 157:159, 161:168)] #for use with LTE5
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)] #for use with LTE10
#Ensure ClassLTE2 is a Factor (Categorical Variable)
#AsTest$ClassLTE2 <- as.factor(AsTest$ClassLTE2)
#AsTest$ClassLTE3 <- as.factor(AsTest$ClassLTE3)
#AsTest$ClassLTE5 <- as.factor(AsTest$ClassLTE5)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
# Predicting the Test set results
#Predictions
y_pred = predict(Arsenic_xgb, newdata = test[,-1], type="prob")
#Join probability with outcome from Test set
#y_predJoin<-cbind(test[,157], y_pred) #change field to match outcome modeled, this applies to LT1
#y_predJoin<-cbind(test[,158], y_pred) #change field to match outcome modeled, this applies to LT2
#y_predJoin<-cbind(test[,159], y_pred) #change field to match outcome modeled, this applies to LT3
#y_predJoin<-cbind(test[,160], y_pred) #change field to match outcome modeled, this applies to LT5
y_predJoin<-cbind(test[,161], y_pred) #change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"PrednoExceed"
colnames(y_predJoin)[3]<-"Predexceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden)
summary(cp)
plot(cp)
#Extract ROC Curve data for plotting
a<-as.data.frame(cp$roc_curve)
a$sens<-a$tp/(a$tp+a$fn) #sensitivity
a$spec<-a$tn/(a$tn+a$fp) #specificity
a$j<-(a$tp/(a$tp+a$fn))+(a$tn/(a$tn+a$fp))-1 #j-index, also called Youden value
##Make a plot like USGS PFAS paper S8
df <- a %>%
select(x.sorted, j, sens, spec) %>%
gather(key = "variable", value = "value", -x.sorted)
ggplot(df, aes(x = x.sorted, y = value)) +
geom_line(aes(color = variable, linetype = variable)) +
scale_color_manual(values = c("black","darkred", "steelblue")) +
xlab("As Detection Threshold - value above this threshold is considered a detection") + ylab("Metric Estimate")
#Assign predicted class using ROC threshold from previous steps
y_pred$class<-0
#y_pred$class[y_pred$'1' > 0.1258]<-1 #for LTE1
#y_pred$class[y_pred$'1' > 0.6034]<-1 #for LTE2
#y_pred$class[y_pred$'1' > 0.6023]<-1 #for LTE3
#y_pred$class[y_pred$'1' > 0.1405]<-1 #for LTE5
y_pred$class[y_pred$'1' > 0.1259]<-1 #for LTE10
#
# Confusion Matrix
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE1, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE2, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE3, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE5, positive = '1')
confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE10, positive = '1', mode="sens_spec")
confusion_mtx
# Plotting model
plot(Arsenic_xgb)
# Calculate Accuracy
accuracy <- confusion_mtx$overall['Accuracy']
accuracy
# Calculate kappa value
kappa_value <- confusion_mtx$overall['Kappa']
kappa_value
# Extract Sensitivity and Specificity for each class
sensitivity <- confusion_mtx$byClass[[1]]
sensitivity
specificity <- confusion_mtx$byClass[[2]]
specificity
# training data accuracy and kappa
# AvgAcc = accuracy  Avgkap = kappa
Arsenic_xgb$resample %>%
arrange(Resample) %>%
mutate(AvgAcc = mean(Accuracy)) %>%
mutate(Avgkap = mean(Kappa))
ddd<-Arsenic_xgb$results
write.csv(ddd, file="20241208_As10_xgbAs_tuningOutput.csv")
max(Arsenic_xgb$results[[8]])
library(caTools)
#library(randomForest)
library(gbm)
library(xgboost) # for xgboost
library(caret)
library(tidyverse)
#install.packages("cutpointr") #install only once then comment out
library(cutpointr)
#setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
=======
library(dplyr)
#Clean up the workspace
>>>>>>> 09ef70c64437e823b53c4085b7fb05e48493cf5c
rm(list=ls())
#Load data
Nure <- read.csv("./02_uranium/01_data/Nure7_Data_ExportTable.csv")
WQP <- read.csv("./02_uranium/01_data/wqpData_cleaned_20240808.csv", na.strings = "NULL")
NNwells <- read.csv("./02_uranium/01_data/nnwells3_Check_ExportTable.csv")
#Rename fields in NURE dataset
Nure <- Nure %>%
rename(baseflow = bfi48grd_ProjectRaster2, prism30yr = PRISM_ppt_30yr_ProjectRaster1, U = u_fl_ppb)
#Rename fields in WQP Data
WQP<- WQP %>%
rename(baseflow = bfi48grd,
prism30yr = PRISM_30yrNorm,
welldpth = WellDepthMeasureValue,
As = ResultMeasureValue,
F30mElevationFoCo = F30mElevat)
#str(NNwells$SiteID)
#combine data sets
combined_data <- bind_rows(Nure, WQP)
combined_data1 <- bind_rows(combined_data, NNwells)#
#Need to find missing fields then create new blank fields, i started by comparing data and data1, need to repeat for data2
a<-colnames(Nure)
b<-colnames(WQP)
c<-colnames(NNwells)
setdiff(c, a)
setdiff(c, b)
setdiff(a, b) #this will tell you the fields that don't match between a and b, anything not matching needs to be added to b, shows what data is in a that is not in b
setdiff(b, a) #this will tell you the fields that don't match between b and a, anything not matching needs to be added to a
setdiff(a, c)
setdiff(b, c)
setdiff(c, b)
setdiff(c, a)
#Load libraries
library(reshape2)
library(dplyr)
library(tidyr)
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
getwd()
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
setwd("\\10.192.74.47\HooverShare\Shared_Group_Data")
setwd("//10.192.74.47/HooverShare/Shared_Group_Data")
setwd("/10.192.74.47/HooverShare/Shared_Group_Data")
#Set working directory
setwd("/Volumes/HooverShare/Shared_Group_Data/20_projects/06_coPlateau_Rework/")
#Clean up the workspace
rm(list=ls())
#Load csv files
a<-read.csv("./02_Data/Raw_Data/WQP/00_archive/AZ_Uranium.csv", na.strings = "NULL")
b<-read.csv("./02_Data/Raw_Data/WQP/00_archive/NM_Uranium.csv", na.strings = "NULL")
c<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Ca.csv", na.strings = "NULL")
d<-read.csv("./02_Data/Raw_Data/WQP/00_archive/Iron.csv", na.strings = "NULL")
e<-read.csv("./02_Data/Raw_Data/WQP/00_archive/ph.csv", na.strings = "NULL")
f<-read.csv("./02_Data/Raw_Data/WQP/00_archive/alkalinity.csv", na.strings = "NULL")
g<-read.csv("./02_Data/Raw_Data/WQP/00_archive/CO_Uranium.csv", na.strings = "NULL")
h<-read.csv("./02_Data/Raw_Data/WQP/00_archive/UT_Uranium.csv", na.strings = "NULL")
u<-rbind(a,b,g,h)
#Process uranium data (done)
u2 <- u %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(ResultMeasureMeasureUnitCode != "ratio") %>%
filter(CharacteristicName == "U")
summary(factor(u2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(u2$ResultMeasureMeasureUnitCode == "pCi/L") #Create an index with records that we need to convert
u2$ResultMeasureValue[mgL_indices] <- u2$ResultMeasureValue[mgL_indices] * 0.67 #Convert to pCi/L to ug/L match NN Wells analyte data
u2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units mg/L
#Calcium: keep mg/L (done)
c2 <- c %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved")
summary(factor(c2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(c2$ResultMeasureMeasureUnitCode == "ug/l" | c2$ResultMeasureMeasureUnitCode == "ug/L") #Create an index with records that we need to convert
c2$ResultMeasureValue[mgL_indices] <- c2$ResultMeasureValue[mgL_indices] / 1000 #Convert to mg/L to match NN Wells analyte data
c2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Iron: unit conversions (done)
d2 <- d %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Dissolved") %>%
filter(CharacteristicName == "Fe") #remove Ferric ion, Ferrous ion, and Iron-59
summary(factor(d2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(d2$ResultMeasureMeasureUnitCode == "mg/l" | d2$ResultMeasureMeasureUnitCode == "mg/L") #Create an index with records that we need to convert
d2$ResultMeasureValue[mgL_indices] <- d2$ResultMeasureValue[mgL_indices] * 1000 #Convert to ug/L to match NN Wells analyte data
d2$ResultMeasureMeasureUnitCode <- "ug/L"   # made all units ug/L
#pH - check that all measurements are in standard units (done)
e2 <- e %>%
drop_na(ResultMeasureMeasureUnitCode) %>%
filter(ResultSampleFractionText == "Total")
#summary(factor(e2$ResultMeasureMeasureUnitCode))
#Alkalinity: convert ug/L to mg/L in ResultMeasureMeasureUnitCode (done)
f2 <- f %>%
drop_na(ResultMeasureMeasureUnitCode) %>%   #Remove rows with NA's using drop_na()
filter(ResultSampleFractionText == "Total") %>% #filter to total results since we want to use raw water samples
filter(CharacteristicName == "Alkalinity")
summary(factor(f2$ResultMeasureMeasureUnitCode)) #Check to see what units are noted in the field
mgL_indices <- which(f2$ResultMeasureMeasureUnitCode == "ug/l") #Create an index with records that we need to convert
f2$ResultMeasureValue[mgL_indices] <- f2$ResultMeasureValue[mgL_indices] / 1000 #Convert to ug/L to match NN Wells analyte data
f2$ResultMeasureMeasureUnitCode <- "mg/L"   # made all units mg/L
#Merge files
cdef<-rbind(c2,d2,e2,f2, u2)
cdef2 <- cdef %>%
filter(StateCode == 4 & (CountyCode == 1 | CountyCode == 5 | CountyCode == 7 | CountyCode == 15 | CountyCode == 17 | CountyCode == 25) |
(StateCode == 35 & (CountyCode == 3 | CountyCode ==6 | CountyCode ==31 | CountyCode ==39 | CountyCode ==43 | CountyCode ==45)) |
(StateCode == 08 & (CountyCode == 29 | CountyCode == 33 | CountyCode == 45 | CountyCode ==67 | CountyCode ==77 | CountyCode ==81 | CountyCode ==83 | CountyCode ==85 | CountyCode ==91 | CountyCode ==103 | CountyCode ==113)) |
(StateCode == 49 & (CountyCode == 1 | CountyCode == 7 | CountyCode ==13 | CountyCode ==15 | CountyCode ==17 | CountyCode == 19 | CountyCode ==21 | CountyCode ==23 | CountyCode ==25 | CountyCode ==27 | CountyCode ==31 | CountyCode == 37 | CountyCode ==39 | CountyCode ==41 | CountyCode ==47 | CountyCode ==49 | CountyCode ==51 | CountyCode == 53 | CountyCode ==55)))
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName+ResultMeasureMeasureUnitCode, value.var="ResultMeasureValue", median)
View(wide)
#convert to wide format
wide<-dcast(cdef2, SiteID~CharacteristicName, value.var="ResultMeasureValue", median)
View(wide)
#Read GIS data from WQP
i<-read.csv("./02_Data/Raw_Data/WQP/00_archive/20241029_WQP_Export.csv", na.strings = "NULL")
View(i)
#Clean up new dataframe, drop worthless fields
cleani<- i [-c(2:25,27:79)]
View(cleani)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
View(WQP_All)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.y=TRUE)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
?distinct
#Return unique records
yourDataFrame <- i %>%
distinct(cleani .keep_all = TRUE)
#Return unique records
yourDataFrame <- i %>%
distinct(cleani, .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = TRUE)
#Return unique records
df <- i %>%
distinct(cleani[, 1:155])
#Return unique records
df <- i %>%
distinct(cleani[, 1:155], .keep_all = FALSE)
#Return unique records
cleanNoDup<-distinct(cleani)
View(cleanNoDup)
#Return unique records
cleanNoDup<-distinct(cleani[,c(2:155)])
View(cleanNoDup)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleani, by="SiteID", all.x=TRUE)
View(WQP_All)
#class(cleani[["SiteID"]])
#class(wide[["SiteID"]])
#Merge with wide using SiteID
WQP_All<-merge(wide, cleanNoDup, by="SiteID", all.x=TRUE)
View(WQP_All)
version()
version
library(caTools)
library(caret)
library(gbm)
library(xgboost) # for xgboost
library("SHAPforxgboost")
library(data.table)
#library(tidyverse) # general utility functions
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 4,
subsample = 0.5,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
##XGB Train
for(data in 1:10){
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 1000, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y); print(xy)
dfAc<-rbind(dfAc, xy)
}
#Clean up and write to file
colnames(dfAc)[1]<-"Train_Error"
colnames(dfAc)[2]<-"Test_Error"
mean(dfAc$Train_Error)
sd(dfAc$Train_Error)
mean(dfAc$Test_Error)
sd(dfAc$Test_Error)
#Testing Data
xgbpred <- predict (model, xgb_test)
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y))
# Compute feature importance matrix
importance_matrix = xgb.importance(colnames(xgb_train), model = model)
head(importance_matrix)
# Nice graph
xgb.plot.importance(importance_matrix[1:125,])
library(tidyverse)
qqq <- importance_matrix %>%
arrange(Gain)  # arrange in descending order
head(qqq)
125-113
# Nice graph
xgb.plot.importance(importance_matrix[1:12,])
# Nice graph
xgb.plot.importance(importance_matrix[1:13,])
# Nice graph
xgb.plot.importance(importance_matrix[1:12,])
#Make a list of the fewest number of variables with the highest overall prediction accuracy
#highest accuracy is 0.768 using 12 variables with the highest gain values - from the csv output from step 2
a<-list("pH","Fe","A_Calcite","prism30yr","DepthToGW","C_Sb","A_Kaolinit","C_Tot_14A","C_Hematite","Top5_Ca","A_Tot_Flds","C_Se")
a
View(train)
#define predictor and response variables in training set, As= 5 ug/L, keep variables defined above
train_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
View(train_x)
#train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
library(caTools)
library(caret)
library(gbm)
library(xgboost) # for xgboost
library("SHAPforxgboost")
library(data.table)
#library(tidyverse) # general utility functions
# load arguments
#args<-commandArgs(TRUE)
## Input files and directories
#in_path=args[1]
#out_pathDir=args[2]
#tune_var=args[3]
#gamma=args[4]
#min_child_weight=args[5]
#print(in_path)
#print(out_pathDir)
#print(alpha)
#print(lambda)
#print(gamma)
#print(max_delta_step)
#print(min_child_weight)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE10_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE10_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
<<<<<<< HEAD
#Drop unused fields
#AsTrain<-train[,-c(1, 4, 109:112, 157, 159:168)] #Drop the As concentration, and the categorical variables we already transformed
#AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)] #for use with LTE1
#AsTest<-test[,-c(1, 4, 109:112, 157,159:168)] #for use with LTE2
#AsTest<-test[,-c(1, 4, 109:112, 157:158, 160:168)] #for use with LTE3
#AsTest<-test[,-c(1, 4, 109:112, 157:159, 161:168)] #for use with LTE5
AsTest<-test[,-c(1, 4, 109:112, 157:160, 162:168)] #for use with LTE10
#Ensure ClassLTE2 is a Factor (Categorical Variable)
#AsTest$ClassLTE2 <- as.factor(AsTest$ClassLTE2)
#AsTest$ClassLTE3 <- as.factor(AsTest$ClassLTE3)
#AsTest$ClassLTE5 <- as.factor(AsTest$ClassLTE5)
AsTest$ClassLTE10  <- as.factor(AsTest$ClassLTE10)
# Predicting the Test set results
#Predictions
y_pred = predict(Arsenic_xgb, newdata = test[,-1], type="prob")
#Join probability with outcome from Test set
#y_predJoin<-cbind(test[,157], y_pred) #change field to match outcome modeled, this applies to LT1
#y_predJoin<-cbind(test[,158], y_pred) #change field to match outcome modeled, this applies to LT2
#y_predJoin<-cbind(test[,159], y_pred) #change field to match outcome modeled, this applies to LT3
#y_predJoin<-cbind(test[,160], y_pred) #change field to match outcome modeled, this applies to LT5
y_predJoin<-cbind(test[,161], y_pred) #change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"PrednoExceed"
colnames(y_predJoin)[3]<-"Predexceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden)
=======
#Make a list of the fewest number of variables with the highest overall prediction accuracy
#highest accuracy is 0.768 using 12 variables with the highest gain values - from the csv output from step 2
a<-list("pH","Fe","A_Calcite","prism30yr","DepthToGW","C_Sb","A_Kaolinit",
"C_Tot_14A","C_Hematite","Top5_Ca","A_Tot_Flds","C_Se")
a
#define predictor and response variables in training set, As= 5 ug/L, keep variables defined above
train_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Make a list of the fewest number of variables with the highest overall prediction accuracy
#highest accuracy is 0.768 using 12 variables with the highest gain values - from the csv output from step 2
a<-list("pH","Fe","A_Calcite","prism30yr","DepthToGW","C_Sb","A_Kaolinit",
"C_Tot_14A","C_Hematite","Top5_Ca","A_Tot_Flds","C_Se")
a
#define predictor and response variables in training set, As= 5 ug/L, keep variables defined above
train_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[,160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define predictor and response variables in testing set
test_x = data.matrix(test[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[,160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Make a list of the fewest number of variables with the highest overall prediction accuracy
#highest accuracy is 0.768 using 12 variables with the highest gain values - from the csv output from step 2
a<-list("pH","Fe","A_Calcite","prism30yr","DepthToGW","C_Sb","A_Kaolinit",
"C_Tot_14A","C_Hematite","Top5_Ca","A_Tot_Flds","C_Se")
a
#define predictor and response variables in training set, As= 5 ug/L, keep variables defined above
train_x = data.matrix(train[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, c(1, 3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[,160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Set parameters from all the tuning
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.005,
max_depth = 6,
subsample = 0.50,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
#Fully tuned model
model = xgboost(data = xgb_train, params = params,
nrounds = 750, objective = "binary:logistic",
eval_metric = "error", verbose = 1,
print_every_n = 100)
#Testing Data
xgbpred <- predict (model, xgb_test)
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y))
#Adjust the "true" threshold using Youden value
#For a figure
y_predJoin<-data.frame(cbind(test_y, xgbpred))#change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"Predexceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden)
library("SHAPforxgboost")
library(data.table)
library(cutpointr)
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden)
?cutpointr
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden, pot_class = 1)
>>>>>>> 09ef70c64437e823b53c4085b7fb05e48493cf5c
summary(cp)
plot(cp)
#Extract ROC Curve data for plotting
a<-as.data.frame(cp$roc_curve)
a$sens<-a$tp/(a$tp+a$fn) #sensitivity
a$spec<-a$tn/(a$tn+a$fp) #specificity
a$j<-(a$tp/(a$tp+a$fn))+(a$tn/(a$tn+a$fp))-1 #j-index, also called Youden value
##Make a plot like USGS PFAS paper S8
df <- a %>%
select(x.sorted, j, sens, spec) %>%
gather(key = "variable", value = "value", -x.sorted)
ggplot(df, aes(x = x.sorted, y = value)) +
geom_line(aes(color = variable, linetype = variable)) +
scale_color_manual(values = c("black","darkred", "steelblue")) +
xlab("As Detection Threshold - value above this threshold is considered a detection") + ylab("Metric Estimate")
<<<<<<< HEAD
#Assign predicted class using ROC threshold from previous steps
y_pred$class<-0
#y_pred$class[y_pred$'1' > 0.1258]<-1 #for LTE1
#y_pred$class[y_pred$'1' > 0.6034]<-1 #for LTE2
#y_pred$class[y_pred$'1' > 0.6023]<-1 #for LTE3
#y_pred$class[y_pred$'1' > 0.1405]<-1 #for LTE5
y_pred$class[y_pred$'1' > 0.1259]<-1 #for LTE10
#
# Confusion Matrix
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE1, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE2, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE3, positive = '1')
#confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE5, positive = '1')
confusion_mtx <- confusionMatrix(factor(y_pred$class), AsTest$ClassLTE10, positive = '1', mode="sens_spec")
confusion_mtx
# Plotting model
plot(Arsenic_xgb)
# Calculate Accuracy
accuracy <- confusion_mtx$overall['Accuracy']
accuracy
# Calculate kappa value
kappa_value <- confusion_mtx$overall['Kappa']
kappa_value
# Extract Sensitivity and Specificity for each class
sensitivity <- confusion_mtx$byClass[[1]]
sensitivity
specificity <- confusion_mtx$byClass[[2]]
specificity
# training data accuracy and kappa
# AvgAcc = accuracy  Avgkap = kappa
Arsenic_xgb$resample %>%
arrange(Resample) %>%
mutate(AvgAcc = mean(Accuracy)) %>%
mutate(Avgkap = mean(Kappa))
ddd<-Arsenic_xgb$results
write.csv(ddd, file="20241208_As10_xgbAs_tuningOutput.csv")
max(Arsenic_xgb$results[[8]])
=======
# To prepare the long-format data:
shap_long <- shap.prep(xgb_model = model, X_train = train_x)
# **SHAP summary plot**
shap.plot.summary(shap_long)
#define predictor and response variables in training set, As= 5 ug/L, keep variables defined above
train_x = data.matrix(train[, c(3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, c(3, 2, 27,5, 108,87,38,106, 99,11,60,88)])
test_y = test[,160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Set parameters from all the tuning
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.005,
max_depth = 6,
subsample = 0.50,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
#Fully tuned model
model = xgboost(data = xgb_train, params = params,
nrounds = 750, objective = "binary:logistic",
eval_metric = "error", verbose = 1,
print_every_n = 100)
#Testing Data
xgbpred <- predict (model, xgb_test)
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y))
#Adjust the "true" threshold using Youden value
#For a figure
y_predJoin<-data.frame(cbind(test_y, xgbpred))#change field to match outcome modeled, this applies to LT10
#rename fields for ease of use
colnames(y_predJoin)[1]<-"Obsclass"
colnames(y_predJoin)[2]<-"Predexceed"
#Use cutpoint to identify threshold for As 'detection' balancing sensitivity and specificity using Youden metric
cp <- cutpointr(y_predJoin, Predexceed, Obsclass,
method = maximize_metric, metric = youden, pot_class = 1)
summary(cp)
plot(cp)
#Extract ROC Curve data for plotting
a<-as.data.frame(cp$roc_curve)
a$sens<-a$tp/(a$tp+a$fn) #sensitivity
a$spec<-a$tn/(a$tn+a$fp) #specificity
a$j<-(a$tp/(a$tp+a$fn))+(a$tn/(a$tn+a$fp))-1 #j-index, also called Youden value
##Make a plot like USGS PFAS paper S8
df <- a %>%
select(x.sorted, j, sens, spec) %>%
gather(key = "variable", value = "value", -x.sorted)
ggplot(df, aes(x = x.sorted, y = value)) +
geom_line(aes(color = variable, linetype = variable)) +
scale_color_manual(values = c("black","darkred", "steelblue")) +
xlab("As Detection Threshold - value above this threshold is considered a detection") + ylab("Metric Estimate")
# To prepare the long-format data:
shap_long <- shap.prep(xgb_model = model, X_train = train_x)
# **SHAP summary plot**
shap.plot.summary(shap_long)
>>>>>>> 09ef70c64437e823b53c4085b7fb05e48493cf5c
