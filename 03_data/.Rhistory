xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 8,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
##XGB Train
for(data in 1:10){
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 500, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y)
dfAc<-rbind(dfAc, xy)
}
#Clean up and write to file
colnames(dfAc)[1]<-"Train_Error"
colnames(dfAc)[2]<-"Test_Error"
mean(dfAc$Train_Error)
sd(dfAc$Train_Error)
mean(dfAc$Test_Error)
sd(dfAc$Test_Error)
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:159, 161:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:159, 161:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 8,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 500, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
summary(factor(train_y))
summary(factor(test_y))
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 8,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 500, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
View(train_x)
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 8,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 500, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y)
dfAc<-rbind(dfAc, xy)
View(dfAc)
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.0125,
max_depth = 8,
subsample = 0.5,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 500, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y)
xy
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-08_ClassLTE10_cv10_xgb.rds")
Arsenic_xgb<-readRDS("./XGB_rds/2024-12-05_ClassLTE5_cv10_xgb.rds")
Arsenic_xgb
#Make SiteID the row name so we can drop that field
#rownames(train)<-train$SiteID
ddd<-Arsenic_xgb$results
#identify maximum accuracy and then calculate 1 Se model threshold
a<-max(ddd$Accuracy); print(a) #accuracy
b<-ddd$AccuracySD[ddd$Accuracy==a] #standard deviation of 'best' model
se<-b/sqrt(10); print(se) #1 standard error
aSe<-a-se; print(aSe) #'best' model minus 1 SE
#Filter to movdels with accuracy within 1 SE
dd3 <- ddd %>%
filter(Accuracy >= aSe)
#Now filter by variable order, eta, max depth, nrounds
shrink<-min(dd3$eta); print(shrink)
dd4 <- dd3 %>%
filter(eta == shrink)
View(dd4)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.005,
max_depth = 12,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 750, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y); print(xy)
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-08_ClassLTE10_cv10_xgb.rds")
Arsenic_xgb<-readRDS("./XGB_rds/2024-12-05_ClassLTE5_cv10_xgb.rds")
Arsenic_xgb
#Make SiteID the row name so we can drop that field
#rownames(train)<-train$SiteID
ddd<-Arsenic_xgb$results
#identify maximum accuracy and then calculate 1 Se model threshold
a<-max(ddd$Accuracy); print(a) #accuracy
b<-ddd$AccuracySD[ddd$Accuracy==a] #standard deviation of 'best' model
se<-b/sqrt(10); print(se) #1 standard error
aSe<-a-se; print(aSe) #'best' model minus 1 SE
#Filter to movdels with accuracy within 1 SE
dd3 <- ddd %>%
filter(Accuracy >= aSe)
#Now filter by variable order, eta, max depth, nrounds
shrink<-min(dd3$eta); print(shrink)
dd4 <- dd3 %>%
filter(eta < 0.0125)
View(dd4)
dd4 <- dd3 %>%
filter(eta < 0.0125) %>%
filter(max_depth<=8)
View(dd4)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.0075,
max_depth = 8,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 750, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y); print(xy)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 4,
subsample = 0.5,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 1000, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y); print(xy)
dfAc<-rbind(dfAc, xy)
#Clean up and write to file
colnames(dfAc)[1]<-"Train_Error"
colnames(dfAc)[2]<-"Test_Error"
mean(dfAc$Train_Error)
sd(dfAc$Train_Error)
mean(dfAc$Test_Error)
sd(dfAc$Test_Error)
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Arsenic_xgb<-readRDS("./XGB_rds/2024-12-08_ClassLTE10_cv10_xgb.rds")
Arsenic_xgb<-readRDS("./XGB_rds/2024-12-05_ClassLTE5_cv10_xgb.rds")
Arsenic_xgb
#Make SiteID the row name so we can drop that field
#rownames(train)<-train$SiteID
ddd<-Arsenic_xgb$results
#identify maximum accuracy and then calculate 1 Se model threshold
a<-max(ddd$Accuracy); print(a) #accuracy
b<-ddd$AccuracySD[ddd$Accuracy==a] #standard deviation of 'best' model
se<-b/sqrt(10); print(se) #1 standard error
aSe<-a-se; print(aSe) #'best' model minus 1 SE
#Filter to movdels with accuracy within 1 SE
dd3 <- ddd %>%
filter(Accuracy >= aSe)
#Now filter by variable order, eta, max depth, nrounds
shrink<-min(dd3$eta); print(shrink)
depth<-min(dd3$max_depth); print(depth)
dd4 <- dd3 %>%
filter(eta < 0.0125) %>%
filter(max_depth == depth)
View(dd4)
dd4 <- dd3 %>%
filter(eta < 0.0125) %>%
filter(max_depth == depth)
#best, most simple model
print(dd4) #use these parameters to train model using full training set, post process step 2
rm(list=ls())
# set data and seed values
date<-Sys.Date()
set.seed(1234)  # Setting seed
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#Load data
#Asdata = read.csv(in_path, na.strings = "NULL")
Asdata = read.csv("All_As_Data.csv", na.strings = "NULL")
# Filter data into train and test sets based on logical variable
train <- Asdata[Asdata$trainClassLTE5_splt == TRUE, ]
test <- Asdata[Asdata$trainClassLTE5_splt == FALSE, ]
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#define predictor and response variables in training set, As= 5 ug/L
train_x = data.matrix(train[, -c(1, 4, 109:112, 157:168)])
train_y = train[,160]
#define predictor and response variables in testing set
test_x = data.matrix(test[, -c(1, 4, 109:112, 157:168)])
test_y = test[, 160]
#define final training and testing sets
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
xgb_test = xgb.DMatrix(data = test_x, label = test_y)
#define watchlist
watchlist = list(train=xgb_train, test=xgb_test)
#Run model 10 times and calculate accuarcy and SD of accuracy, change hyperparameter value as needed
dfAc<-data.frame()
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.01,
max_depth = 4,
subsample = 0.5,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
##XGB Train
for(data in 1:10){
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 1000, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y); print(xy)
dfAc<-rbind(dfAc, xy)
}
#Clean up and write to file
colnames(dfAc)[1]<-"Train_Error"
colnames(dfAc)[2]<-"Test_Error"
mean(dfAc$Train_Error)
sd(dfAc$Train_Error)
mean(dfAc$Test_Error)
sd(dfAc$Test_Error)
write.csv(dfAc, file="20241223_as5ugL_modelTuning_primaryHyperparameters.csv")
#Testing Data
xgbpred <- predict (model, xgb_test)
xgbpred2 <- ifelse (xgbpred > 0.5,1,0)
confusionMatrix (factor(xgbpred2), factor(test_y))
write.csv(dfAc, file="20241223_as5ugL_modelTuning_primaryHyperparameters.csv")
#Determine variable importance
# Compute feature importance matrix
importance_matrix = xgb.importance(colnames(xgb_train), model = model)
head(importance_matrix)
# Compute feature importance matrix
importance_matrix = xgb.importance(colnames(xgb_train), model = model)
head(importance_matrix)
##
library(tidyverse)
qqq <- importance_matrix %>%
arrange(Gain)  # arrange in descending order
head(qqq)
#importanceList<-data.frame(lapply(importance_matrix, sort))
qqq$filterID<-seq(length(qqq$Gain))
View(qqq)
library(reshape2)
library(tidyverse)
#Make data training data long format for easy filtering
dfMetrics<-data.frame()
#Make data training data long format for easy filtering
dfMetrics<-data.frame()
for (i in 1:length(qqq$Gain)){
trainL<-melt(train_x)
colnames(trainL)[1]<-"SiteId"
colnames(trainL)[2]<-"Feature"
trainL2<-merge(trainL, qqq, by="Feature")
#Filter based on iteration
trainData2<-trainL2 %>%
filter(filterID > 0+i)
#Convert back to wide format
train_x2<-dcast(trainData2[,c(1:3)], SiteId~Feature, value.var = "value")
train_x3<-data.matrix(train_x2)
#Prep test data
testL<-melt(test_x)
colnames(testL)[1]<-"SiteId"
colnames(testL)[2]<-"Feature"
testL2<-merge(testL, qqq, by="Feature")
testData2<-testL2 %>%
filter(filterID >=0+i)
test_x2<-dcast(testData2[,c(1:3)], SiteId~Feature, value.var = "value")
test_x3<-data.matrix(test_x2)
#define final training and testing sets
xgb_train3 = xgb.DMatrix(data = train_x3, label = train_y)
xgb_test3 = xgb.DMatrix(data = test_x3, label = test_y)
#define watchlist
watchlist3 = list(train=xgb_train3, test=xgb_test3)
params = list(alpha = 0,
lambda = 1,
gamma = 0,
max_delta_step = 0,
eta = 0.005,
max_depth = 6,
subsample = 0.50,
colsample_bytree = 0.75,
min_child_weight = 1,
booster = "gbtree")
dfAd<-data.frame()
##XGB Train
for(w in 1:5){
model = xgb.train(data = xgb_train, params = params,
watchlist = watchlist,
nrounds = 750, objective = "binary:logistic",
eval_metric = list("error"), verbose = 1,
print_every_n = 100)
x<-1-last(model$evaluation_log$train_error)
y<-1-last(model$evaluation_log$test_error)
xy<-cbind(x,y)
dfAd<-rbind(dfAd, xy)
}
#Clean up and write to file
#colnames(dfAc)[1]<-"Train_Error"
#colnames(dfAc)[2]<-"Test_Error"
ab<-mean(dfAd[[1]])
ac<-sd(dfAd[[1]])
ad<-mean(dfAd[[2]])
ae<-sd(dfAd[[2]])
abc<-cbind(i,ab,ac,ad,ae)
dfMetrics<-rbind(dfMetrics, abc)
print(i)
}
View(dfMetrics)
colnames(dfMetrics)[2]<-"Train_Error"
colnames(dfMetrics)[3]<-"Train_SD"
colnames(dfMetrics)[4]<-"Test_Error"
colnames(dfMetrics)[5]<-"Test_SD"
write.csv(dfMetrics, file="20241226_as5XGB_variableDrop_accuracySDImpacts.csv")
ggplot(dfMetrics, aes(x="i", v="Test_Error"))+geom_line()
ggplot(dfMetrics, aes(x="i", y="Test_Error"))+geom_line()
ggplot(dfMetrics, aes(x=i, y=Test_Error))+geom_line()
View(importance_matrix)
# Nice graph
xgb.plot.importance(importance_matrix[1:125,])
