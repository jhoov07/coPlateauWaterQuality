# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'spl3cat'
train <- Asdata[Asdata$spl3cat == TRUE, ]
test <- Asdata[Asdata$spl3cat == FALSE, ]
View(Asdata2)
rm(list=ls())
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'spl3cat'
train <- Asdata[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines21-24
test <- Asdata[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines21-24
View(train)
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
View(train)
rownames(test)<-test$SiteID
View(train)
# Filter data into train and test sets based on logical variable 'spl3cat'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'spl3cat'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
View(test)
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
View(train)
View(train)
#Set working directory
setwd("/Users/hoover/Desktop/")
#Clear environment
rm(list=ls())
#Load data files
#bio<-read.csv("bios.csv", na.strings = "NA")
#lcs<-read.csv("lsc.csv", na.strings = "NA")
#pcd<-read.csv("pcd.csv", na.strings = "NA")
#saw<-read.csv("saw.csv", na.strings = "NA")
#Merge into one data frame
#all<-smartbind(bio, lcs, pcd, saw)
#write.csv(all, file="20241120_envsAllSubPlans_courses.csv")
all<-read.csv("20241120_envsAllSubPlans_courses.csv")
allL<-melt(all, id.vars=c("SubPlan","Subject","Catalog_Num"))
allL2<-allL %>%
drop_na() %>%
filter(variable == 'Total') %>%
filter(value>=7)
allW<-dcast(allL2, SubPlan~Subject+Catalog_Num, value.var="value", sum)
rownames(allW)<-allW$SubPlan
#Remove subplan field and make into a matrix
data <- as.matrix(allW[,-1])
heatmap.2(data, scale = "row", col = bluered(30), sepcolor = "white", sepwidth = c(0.05,0.05),
trace = "row", tracecol = "black", density.info = "histogram")
allL2<-allL %>%
drop_na() %>%
filter(variable == 'Total') %>%
filter(value>=5)
allW<-dcast(allL2, SubPlan~Subject+Catalog_Num, value.var="value", sum)
rownames(allW)<-allW$SubPlan
#Remove subplan field and make into a matrix
data <- as.matrix(allW[,-1])
#Create heatmap
library(gplots)
heatmap.2(data, scale = "row", col = bluered(30), sepcolor = "white", sepwidth = c(0.05,0.05),
trace = "row", tracecol = "black", density.info = "histogram")
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
View(train)
#Drop unused fields
AsTrain<-train[,-c(109:112, 157:163)] #Drop the SiteID, and the classification fields
AsTest<-test[,-c(109:112, 157:163)]
#Libraries
library(reshape2)
#Set working directory
setwd("/Users/hoover/Desktop/")
#Clear environment
rm(list=ls())
#Load data files
#bio<-read.csv("bios.csv", na.strings = "NA")
#lcs<-read.csv("lsc.csv", na.strings = "NA")
#pcd<-read.csv("pcd.csv", na.strings = "NA")
#saw<-read.csv("saw.csv", na.strings = "NA")
#Merge into one data frame
#all<-smartbind(bio, lcs, pcd, saw)
#write.csv(all, file="20241120_envsAllSubPlans_courses.csv")
all<-read.csv("20241120_envsAllSubPlans_courses.csv")
allL<-melt(all, id.vars=c("SubPlan","Subject","Catalog_Num"))
allL2<-allL %>%
drop_na() %>%
filter(variable == 'Total') %>%
filter(value>=5)
allW<-dcast(allL2, SubPlan~Subject+Catalog_Num, value.var="value", sum)
rownames(allW)<-allW$SubPlan
#Remove subplan field and make into a matrix
data <- as.matrix(allW[,-1])
View(allL2)
View(allW)
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/03_data/")
#setwd("/Users/aaronnuanez/Documents/GitHub/coPlateauWaterQuality/03_data")
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(109:112, 157:162)] #Drop the SiteID, and the classification fields
AsTest<-test[,-c(109:112, 157:162)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
#Drop unused fields
AsTrain<-train[,-c(4, 109:112, 157:162)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(4, 109:112, 157:162)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
#this is the more accurate model out put
#it was ran on the super computer
#classifier_RF = readRDS("/Users/austinmartinez/Documents/GitHub/coPlateauWaterQuality/03_modelOutputs/01_randomForest/2024-07-25_rf.rds")
# This model runs in legit 2 seconds
classifier_RF<-train(
factor(trainCat2) ~ . - SiteID,
data = Asdata2,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
classifier_RF
# Predicting the Test set results
y_pred <- predict(classifier_RF, newdata = AsTest)
# Predicting the Test set results
y_pred <- predict(classifier_RF, newdata = AsTest)
?predict
?train
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(4, 109:112, 157:162)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(4, 109:112, 157:162)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
#AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
#AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
# This model runs in legit 2 seconds
classifier_RF<-train(
factor(trainCat2) ~ . - SiteID,
data = AsTrain,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
# This model runs in legit 2 seconds
classifier_RF<-train(
trainCat2 ~ . - SiteID,
data = AsTrain,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(4, 109:112, 157:162)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(4, 109:112, 157:162)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
# This model runs in legit 2 seconds
classifier_RF<-train(
factor(trainCat2) ~ . - SiteID,
data = AsTrain,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
?train
# This model runs in legit 2 seconds
classifier_RF<-train(
factor(trainCat2) ~ .,
data = AsTrain,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
# This model runs in legit 2 seconds
classifier_RF<-train(
trainCat2 ~ .,
data = AsTrain,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
# This model runs in legit 2 seconds
classifier_RF<-train(
data = AsTrain,
factor(trainCat2) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
View(AsTrain)
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 157:162)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 157:162)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$trainCat2 <- as.factor(AsTrain$trainCat2)
AsTest$trainCat2  <- as.factor(AsTest$trainCat2)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
# This model runs in legit 2 seconds
classifier_RF<-train(
data = AsTrain,
factor(trainCat2) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
summary(AsTrain$trainCat2)
View(train)
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 158:162)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 158:162)]
rm(list=ls())
#Load data
Asdata <- read.csv("All_As_Data.csv")
#take out NAs
#Asdata <- Asdata[complete.cases(Asdata), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep training set balances with overall distribution
sample_set<-sample.split(Asdata$ClassLTE1, SplitRatio = 0.7)
Asdata2 <- Asdata %>%
mutate(
trainCat2 = ifelse(sample_set == TRUE, 1, 0)
)
# Filter data into train and test sets based on logical variable 'trainCat2'
train <- Asdata2[Asdata2$trainCat2 == TRUE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
test <- Asdata2[Asdata2$trainCat2 == FALSE, ] #Need up update this field and dataframe to match what is produce in lines 21-24
#Make SiteID the row name so we can drop that field
rownames(train)<-train$SiteID
rownames(test)<-test$SiteID
#Drop unused fields
AsTrain<-train[,-c(1, 4, 109:112, 158:163)] #Drop the As concentration, and the categorical variables we already transformed
AsTest<-test[,-c(1, 4, 109:112, 158:163)]
#Ensure ClassLTE1 is a Factor (Categorical Variable)
AsTrain$ClassLTE1 <- as.factor(AsTrain$ClassLTE1)
AsTest$ClassLTE1  <- as.factor(AsTest$ClassLTE1)
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:3)) #Change to 1:84 if testing for real, 1:3 was used for model development
#this is the more accurate model out put
#it was ran on the super computer
#classifier_RF = readRDS("/Users/austinmartinez/Documents/GitHub/coPlateauWaterQuality/03_modelOutputs/01_randomForest/2024-07-25_rf.rds")
# This model runs in legit 2 seconds
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE1) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
classifier_RF
# Predicting the Test set results
y_pred <- predict(classifier_RF, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE1)
confusion_mtx
# Plotting model
plot(classifier_RF)
# Calculate Accuracy
accuracy <- confusion_mtx$overall['Accuracy']
accuracy
# Calculate kappa value
kappa_value <- confusion_mtx$overall['Kappa']
kappa_value
# Extract Sensitivity and Specificity for each class
sensitivity <- confusion_mtx$byClass[,"Sensitivity"]
sensitivity
specificity <- confusion_mtx$byClass[,"Specificity"]
specificity
# training data accuracy and kappa
# AvgAcc = accuracy  Avgkap = kappa
classifier_RF$resample %>%
arrange(Resample) %>%
mutate(AvgAcc = mean(Accuracy)) %>%
mutate(Avgkap = mean(Kappa))
# Test data values
accuracy
kappa_value
sensitivity
specificity
importance <- varImp(classifier_RF, scale = FALSE)
# Plot variable importance
plot(importance, top = 10, col = "blue",  main = "Random Forest Classification")
# Fitting Random Forest to the train dataset
tunegrid <- expand.grid(mtry = (1:5)) #Change to 1:84 if testing for real, 1:3 was used for model development
# This model runs in legit 2 seconds
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE1) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
classifier_RF
# Predicting the Test set results
y_pred <- predict(classifier_RF, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE1)
confusion_mtx
# This model runs in legit 2 seconds
classifier_RF<-train(
data = AsTrain,
factor(ClassLTE1) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 5),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE  # Enable verbose output for troubleshooting
)
# Predicting the Test set results
y_pred <- predict(classifier_RF, newdata = AsTest)
# Confusion Matrix
confusion_mtx <- confusionMatrix(y_pred, AsTest$ClassLTE1)
confusion_mtx
classifier_RF
