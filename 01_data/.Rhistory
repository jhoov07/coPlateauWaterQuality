y_pred = predict(classifier_RF, newdata = AsTest[,-c(1:6,213:215, 217)])
# Confusion Matrix
confusion_mtx = table(AsTest[,216], y_pred)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = AsTest[,-c(1:6,213:215, 217)])
# Confusion Matrix
confusion_mtx = table(AsTest[,216], y_pred)
confusion_mtx
View(classifier_RF)
#Set working directory
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/01_data")
#setwd("/Users/austinmartinez/Documents/GitHub/coPlateauWaterQuality/01_data")
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NULL") #Probably need to simplify the path so the script and data are in the same folder for the HPC
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
#
str(AsTrain)
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
str(AsTrain)
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
View(Asdata)
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
#
str(AsTrain)
for(i in seq(length(tunegrid))) {
classifier_RF<-train(
data = AsTrain,
As3Cat ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_Cleaned_As_GIS_Filtered.csv",
na.strings = "NULL") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata %>%
mutate(
As3Cat = ifelse(ResultMeasureValue <= 1, 0,
ifelse(ResultMeasureValue > 1 & ResultMeasureValue < 5, 1,
ifelse(ResultMeasureValue < 10 & ResultMeasureValue > 5, 2, 3)))
)
View(Asdata)
# Drop rows with NA values in predictor varialble fields and outcome for test data
Asdata2 <- Asdata[complete.cases(Asdata[, 7:214]), ]
# get the numb 70/30 training test split
#split into training (70%) and testing set (30%), keep traing set balances with overall distribution
sample_set<-sample.split(Asdata2$As3Cat, SplitRatio = 0.7)
Asdata2 <- Asdata2 %>%
mutate(
trainCat3 = ifelse(sample_set == TRUE, 1, 0)
)
write.csv(Asdata2, "./CoPlateau_As/20240723_randomForest_As_dataClean.csv")
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
#
str(AsTrain)
for(i in seq(length(tunegrid))) {
classifier_RF<-train(
data = AsTrain,
As3Cat ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
summary(AsTrain)
View(AsTrain)
length(tunegrid)
length(paramList)
for(i in seq(length(paramList))) {
classifier_RF<-train(
data = AsTrain,
As3Cat ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
for(i in seq(length(paramList))) {
classifier_RF<-train(
data = AsTrain,
factor(As3Cat) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
Asdata2 <- Asdata[complete.cases(Asdata), ]
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
View(Asdata)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
#
str(AsTrain)
for(i in seq(length(paramList))) {
classifier_RF<-train(
data = AsTrain,
factor(As3Cat) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 2),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
saveRDS(classifier_RF, paste("./",date, "test2_final_model_rf.rds", sep=""))
#Clean up the workspace
rm(list=ls())
#Load RF model
classifier_RF<-readRDS("2024-07-23test2_final_model_rf.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = AsTest[,-c(1:6,213:215, 217)])
# Confusion Matrix
confusion_mtx = table(AsTest[,216], y_pred)
confusion_mtx
y_red
y_pred
length(y_pred)
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = AsTest[,-c(1:6,213:215, 217)])
# Confusion Matrix
confusion_mtx = table(AsTest[,216], y_pred)
confusion_mtx
# Plotting model
plot(classifier_RF)
# - Variable importance
var_importance <- varImpPlot(classifier_RF)
var_importance
# Importance
importance <- importance(classifier_RF)
importance
# Calculate Accuracy
accuracy <- sum(diag(confusion_mtx)) / sum(confusion_mtx)
accuracy
# Calculate kappa value
kappa_value <- kappa(confusion_mtx)
kappa_value
accuracy
kappa_value
# - Variable importance
var_importance <- varImpPlot(classifier_RF)
str(classifier_RF)
# - Variable importance
var_importance <- varImpPlot(classifier_RF)
?varImpPlot
confusion_mtx
confusionMatrix(predictions, validation$diabetes)
?confusionMatrix
confusionMatrix(y_pred, table(AsTest[,216])
confusionMatrix(y_pred, AsTest[,216])
confusionMatrix(y_pred, AsTest[,216])
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(classifier_RF)
# - Variable importance
var_importance <- varImpPlot(classifier_RF)
# Calculate Accuracy
accuracy <- sum(diag(confusion_mtx)) / sum(confusion_mtx)
accuracy
gbmImp <- varImp(classifier_RF, scale = FALSE)
gbmImp
gbmImp <- varImp(classifier_RF, scale = TRUE)
gbmImp
# - Variable importance - why doesn't this work?!
var_importance <- varImpPlot(gbmImp)
# - Variable importance - why doesn't this work?!
Plot(gbmImp)
# - Variable importance - why doesn't this work?!
plot(gbmImp)
# - Variable importance - why doesn't this work?!
plot(gbmImp, top=20)
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Set a tune grid
n<-ncol(AsTrain)-1
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:10) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
#
str(AsTrain)
#tunegrid <- expand.grid(mtry = 1:n) #Change to 1:84 if testing for real, 1:3 was used for model development
tunegrid <- expand.grid(mtry = 1:15) #Change to 1:84 if testing for real, 1:3 was used for model development
#Turn into a list of lists
paramList <- lapply(split(tunegrid, 1:nrow(tunegrid)), as.list)
for(i in seq(length(paramList))) {
classifier_RF<-train(
data = AsTrain,
factor(As3Cat) ~ .,
metric = "Accuracy",
method = "rf",
trControl = trainControl(method="cv", number = 3),    #change number = 10 if doing for real
tuneGrid  = tunegrid,
ntree = 500,
verboseIter = TRUE)  # Enable verbose output for troubleshooting
}
saveRDS(classifier_RF, paste("./",date, "mtry15_cv3_final_model_rf.rds", sep=""))
#Clean up the workspace
rm(list=ls())
#Load RF model
classifier_RF<-readRDS("2024-07-23mtry15_cv3_final_model_rf.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(classifier_RF, newdata = AsTest[,-c(1:6,213:215, 217)])
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(classifier_RF)
#Calculate variable importance
gbmImp <- varImp(classifier_RF, scale = TRUE)
gbmImp
#Plot variable importance
# - Variable importance
plot(gbmImp, top=20)
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
#Clean up the workspace
rm(list=ls())
date<-Sys.Date()
set.seed(1234)  # Setting seed
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to training set
AsTrain<-subset(Asdata, trainCat3==TRUE)
#Ensure As3Cat is a Factor (Categorical Variable)
AsTrain$As3Cat <- as.factor(AsTrain$As3Cat)
#Drop unused fields
AsTrain<-AsTrain[,-c(1:6,213:215, 217)]
# Fitting Random Forest to the train dataset
#classifier_RF
Arsenic_boost <- train(
As3Cat ~ .,  # Specify the target variable as As3Cat
data = AsTrain,
method = "gbm",
trControl = trainControl(
method = "cv",
number = 3,
verboseIter = TRUE  # Enable verbose output for troubleshooting
),
tuneGrid = expand.grid(
"n.trees" = seq(from = 1000, to = 5000, by = 500),  #from USGS paper, might want to scale down for our work here
"interaction.depth" = seq(from = 2, to = 16, by = 4),  #adapted from USGS paper, might want to scale down for our work here
"shrinkage" = seq(from = 0.004, to = 0.012, by = 0.004),  #adapted from USGS paper, might want to scale down for our work here
"n.minobsinnode" = 8) #from USGS paper, might want to scale down for our work here
)
# Fitting Random Forest to the train dataset
#classifier_RF
Arsenic_boost <- train(
As3Cat ~ .,  # Specify the target variable as As3Cat
data = AsTrain,
method = "gbm",
trControl = trainControl(
method = "cv",
number = 3,
verboseIter = TRUE  # Enable verbose output for troubleshooting
),
tuneGrid = expand.grid(
"n.trees" = seq(from = 100, to = 500, by = 10),  #from USGS paper, might want to scale down for our work here
"interaction.depth" = seq(from = 2, to = 16, by = 2),  #adapted from USGS paper, might want to scale down for our work here
"shrinkage" = seq(from = 0.004, to = 0.012, by = 0.002),  #adapted from USGS paper, might want to scale down for our work here
"n.minobsinnode" = 8) #from USGS paper, might want to scale down for our work here
)
saveRDS(Arsenic_boost, paste("./",date, "cv3_final_model_brt.rds", sep=""))
warnings()
#Clean up the workspace
rm(list=ls())
#Clean up the workspace
rm(list=ls())
#Load RF model
Arsenic_boost<-readRDS("2024-07-23cv3_final_model_brt.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(Arsenic_boost, newdata = AsTest[,-c(1:6,213:215, 217)])
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(Arsenic_boost)
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale = TRUE)
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale = TRUE)
gbmImp
#Plot variable importance
# - Variable importance
plot(gbmImp, top=20)
#Clean up the workspace
rm(list=ls())
#Load RF model
Arsenic_boost<-readRDS("2024-07-23cv3_final_model_brt.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(Arsenic_boost, newdata = AsTest[,-c(1:6,213:215, 217)])
length(y_pred)
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(Arsenic_boost)
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale = TRUE)
#Calculate variable importance
gbmImp <- summary.gbm(Arsenic_boost, scale = TRUE)
library(gbm)
library(gbm)
library(caTools)
library(randomForest)
library(caret)
library(tidyverse)
library(gbm)
#Set working directory
setwd("/Users/hoover/Documents/GitHub/coPlateauWaterQuality/01_data")
#setwd("/Users/austinmartinez/Documents/GitHub/coPlateauWaterQuality/01_data")
#Clean up the workspace
rm(list=ls())
#Load RF model
Arsenic_boost<-readRDS("2024-07-23cv3_final_model_brt.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(Arsenic_boost, newdata = AsTest[,-c(1:6,213:215, 217)])
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(Arsenic_boost)
#Calculate variable importance
gbmImp <- summary.gbm(Arsenic_boost, scale = TRUE)
#Calculate variable importance
gbmImp <- summary.gbm(Arsenic_boost)
summary.gbm(Arsenic_boost)
?summary.gbm
Arsenic_boost
#Calculate variable importance
gbmImp <- summary.gbm(Arsenic_boost, n.trees=230)
str(Arsenic_boost)
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, n.trees=230)
gbmImp
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost)
gbmImp
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale=F)
gbmImp
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale=T)
gbmImp
#Plot variable importance
# - Variable importance
plot(gbmImp, top=20)
#Clean up the workspace
rm(list=ls())
#Load RF model
Arsenic_boost<-readRDS("2024-07-23cv3_final_model_brt.rds")
#Load data
Asdata = read.csv("./CoPlateau_As/20240723_randomForest_As_dataClean.csv",
na.strings = "NA") #Probably need to simplify the path so the script and data are in the same folder for the HPC
Asdata <- Asdata[complete.cases(Asdata), ]
#Subset to test set
AsTest<-subset(Asdata, trainCat3==FALSE)
# Predicting the Test set results
y_pred = predict(Arsenic_boost, newdata = AsTest[,-c(1:6,213:215, 217)])
# Confusion Matrix
#confusion_mtx = table(AsTest[,216], y_pred)
#confusion_mtx
confusionMatrix(y_pred, factor(AsTest[,216]))
# Plotting model
plot(Arsenic_boost)
#Calculate variable importance
gbmImp <- varImp(Arsenic_boost, scale=T)
gbmImp
#Plot variable importance
# - Variable importance
plot(gbmImp, top=20)
